{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "999d413e-7177-4ab5-a81d-883993f9647b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"/home/brunoperdigao/repos/Plan-Classification-Topologic-DGL\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af3705fb-5d06-4624-a656-f42722cd5f14",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c3936cc9-d0d7-456f-814e-04a29cd96e07",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bruno_perdigao/repos/Plan-Classification-Topologic-DGL/.venv/lib/python3.12/site-packages/torchdata/datapipes/__init__.py:18: UserWarning: \n",
      "################################################################################\n",
      "WARNING!\n",
      "The 'datapipes', 'dataloader2' modules are deprecated and will be removed in a\n",
      "future torchdata release! Please see https://github.com/pytorch/data/issues/1196\n",
      "to learn more and leave feedback.\n",
      "################################################################################\n",
      "\n",
      "  deprecation_warning()\n"
     ]
    }
   ],
   "source": [
    "# Import Libraries\n",
    "import time\n",
    "import sklearn\n",
    "import pandas as pd\n",
    "from topologicpy.DGL import DGL\n",
    "from topologicpy.Dictionary import Dictionary\n",
    "from topologicpy.Topology import Topology\n",
    "from topologicpy.Vertex import Vertex\n",
    "from topologicpy.Graph import Graph\n",
    "from topologicpy.Plotly import Plotly\n",
    "import itertools\n",
    "import dgl\n",
    "import torch\n",
    "import random\n",
    "\n",
    "import dgl.nn as dglnn\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from dgl import save_graphs, load_graphs\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "65fa906b-b606-4746-a023-6d93015a599a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dgl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "22f6a4d1-d488-45ea-9ff6-19734d5a0982",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/bruno_perdigao/repos/Plan-Classification-Topologic-DGL'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "192d64e0-827f-4047-9d9a-3d5a35d65624",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done saving data into cached files.\n",
      "Dataset(\"GraphDGL\", num_graphs=200, save_path=/home/bruno_perdigao/.dgl/GraphDGL)\n"
     ]
    }
   ],
   "source": [
    "path = \"./data3\"\n",
    "dataset = DGL.DatasetByCSVPath(path, numberOfGraphClasses=0,\n",
    "                           nodeATTRKey='feat', edgeATTRKey='feat',\n",
    "                           nodeOneHotEncode=False, nodeFeaturesCategories=[],\n",
    "                           edgeOneHotEncode=False, edgeFeaturesCategories=[], addSelfLoop=False)\n",
    "print(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "847cf7ab-8a98-4a2f-8424-c30b49643260",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, val_data, test_data = dgl.data.utils.split_dataset(dataset, [0.7, 0.1, 0.2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c17fc4c8-7fc2-4c26-bf00-80bf67916fff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset(\"GraphDGL\", num_graphs=200, save_path=/home/bruno_perdigao/.dgl/GraphDGL)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a3d880f-9d40-41fe-94f6-fe48645343d2",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a248d8dc-cb2b-4814-9f06-3b06742b8d10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Contruct a two-layer GNN model\n",
    "# import dgl.nn as dglnn\n",
    "# import torch.nn as nn\n",
    "# import torch.nn.functional as F\n",
    "# class SAGE(nn.Module):\n",
    "#     def __init__(self, in_feats, hid_feats, out_feats):\n",
    "#         super().__init__()\n",
    "#         self.conv1 = dglnn.SAGEConv(\n",
    "#             in_feats=in_feats, out_feats=hid_feats, aggregator_type='mean')\n",
    "#         self.conv2 = dglnn.SAGEConv(\n",
    "#             in_feats=hid_feats, out_feats=out_feats, aggregator_type='mean')\n",
    "\n",
    "#     def forward(self, graph, inputs):\n",
    "#         # inputs are features of nodes\n",
    "#         h = self.conv1(graph, inputs)\n",
    "#         h = F.relu(h)\n",
    "#         h = self.conv2(graph, h)\n",
    "#         return h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e24c9c9a-3b84-470b-b272-092837f8524b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, graph, features, labels, mask):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        logits = model(graph, features)\n",
    "        logits = logits[mask]\n",
    "        labels = labels[mask]\n",
    "        _, indices = torch.max(logits, dim=1)\n",
    "        correct = torch.sum(indices == labels)\n",
    "        return correct.item() * 1.0 / len(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b70000f9-3fb5-4eda-adec-9197707aebae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # print(len(dataset.graphs))\n",
    "# for i, graph in enumerate(dataset.graphs):\n",
    "#     # print(i)\n",
    "#     node_features = graph.ndata['feat']\n",
    "#     # print(node_features)\n",
    "#     node_labels = graph.ndata['label']\n",
    "#     # print(node_labels)\n",
    "#     train_mask = graph.ndata['train_mask']\n",
    "#     valid_mask = graph.ndata['val_mask']\n",
    "#     test_mask = graph.ndata['test_mask']\n",
    "#     n_features = node_features.shape[1]\n",
    "#     # print(n_features)\n",
    "#     n_labels = int(node_labels.max().item() + 1)\n",
    "#     # print(n_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f162c1f1-a7f9-4534-8819-39e309da5551",
   "metadata": {},
   "source": [
    "# Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73621f83-2f0a-457b-a8b0-f3fd6fb45e09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# num_hidden_layers = [2, 3, 4, 5]\n",
    "# num_units_per_layer = [25, 50, 100]\n",
    "# activation_functions = [F.relu, F.tanh]\n",
    "# learning_rates = [0.01, 0.001, 0.0005]\n",
    "# batch_sizes = [16, 32, 64]\n",
    "# aggregator_type = ['mean', 'pool', 'lstm']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1cee4d2f-c20f-4ea5-bebf-4f1f3f81e1fc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def evaluate_selected_model(model):\n",
    "    dictionary = DGL.ModelClassifyNodes(model, test_data.dataset)\n",
    "    \n",
    "    actual = []\n",
    "    for l in dictionary['alllabels']:\n",
    "        actual.extend(l)\n",
    "        \n",
    "    predicted = []\n",
    "    for l in dictionary['allpredictions']:\n",
    "        predicted.extend(l)\n",
    "\n",
    "    result = DGL.Accuracy(actual=actual, predicted=predicted)\n",
    "    accuracy = result['accuracy']\n",
    "    precision = DGL.Precision(actual=actual, predicted=predicted)\n",
    "    recall = DGL.Recall(actual=actual, predicted=predicted)\n",
    "   \n",
    "    return accuracy, precision, recall\n",
    "\n",
    "class SAGE(nn.Module):\n",
    "    def __init__(self, in_feats, hid_feats, out_feats, num_layers, activation, agg_type):\n",
    "        super().__init__()\n",
    "        self.layers = nn.ModuleList()\n",
    "        self.activation = activation\n",
    "        \n",
    "        # Create the specified number of hidden layers\n",
    "        self.layers.append(dglnn.SAGEConv(in_feats=in_feats, out_feats=hid_feats, aggregator_type=agg_type))\n",
    "        for _ in range(num_layers - 1):\n",
    "            self.layers.append(dglnn.SAGEConv(in_feats=hid_feats, out_feats=hid_feats, aggregator_type=agg_type))\n",
    "        self.layers.append(dglnn.SAGEConv(in_feats=hid_feats, out_feats=out_feats, aggregator_type=agg_type))\n",
    "\n",
    "    def forward(self, graph, inputs):\n",
    "        h = inputs\n",
    "        for layer in self.layers[:-1]:\n",
    "            h = layer(graph, h)\n",
    "            h = self.activation(h)  # Apply activation function\n",
    "        h = self.layers[-1](graph, h)  # Last layer without activation\n",
    "        return h\n",
    "\n",
    "\n",
    "def train_with_grid(param_grid):\n",
    "    results = []\n",
    "    \n",
    "    # Iterate over all combinations of hyperparameters\n",
    "    for num_layers, hid_feats, activation, lr, batch_size, agg_type in tqdm(param_grid):\n",
    "        print(f\"Training with layers: {num_layers}, units per layer: {hid_feats}, activation: {activation.__name__}, learning rate: {lr}, batch size: {batch_size}, aggreagator type: {agg_type}\")\n",
    "        \n",
    "        # Initialize model and optimizer\n",
    "        n_features = 8\n",
    "        model = SAGE(in_feats=n_features, hid_feats=hid_feats, out_feats=13, num_layers=num_layers, activation=activation, agg_type=agg_type)\n",
    "        opt = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "        \n",
    "        \n",
    "    \n",
    "        # for i, graph in enumerate(dataset.graphs):\n",
    "        all_graph = dgl.batch(dataset.graphs)\n",
    "            \n",
    "        df = pd.DataFrame(columns=['epoch', 'loss', 'val_acc', 'time'])\n",
    "        for epoch in range(100):\n",
    "            start = time.time()        \n",
    "            node_features = all_graph.ndata['feat']\n",
    "            node_labels = all_graph.ndata['label']\n",
    "            train_mask = all_graph.ndata['train_mask']\n",
    "            valid_mask = all_graph.ndata['val_mask']\n",
    "            test_mask = all_graph.ndata['test_mask']\n",
    "            n_features = node_features.shape[1]\n",
    "            n_labels = int(node_labels.max().item() + 1)\n",
    "\n",
    "            model.train()\n",
    "            # forward propagation by using all nodes\n",
    "            logits = model(all_graph, node_features)\n",
    "            # compute loss\n",
    "            loss = F.cross_entropy(logits[train_mask], node_labels[train_mask])\n",
    "            # compute validation accuracy\n",
    "            acc = evaluate(model, all_graph, node_features, node_labels, valid_mask)\n",
    "            # backward propagation\n",
    "            opt.zero_grad()\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "            total_time = time.time() - start\n",
    "            df.loc[len(df)]={\"epoch\": epoch, \"loss\": loss.item(), \"val_acc\": acc, \"time\": total_time}\n",
    "            # print(loss.item())\n",
    "\n",
    "        accuracy, precision, recall = evaluate_selected_model(model)  \n",
    "        result = {\n",
    "            'num_hidden_layers': num_layers,\n",
    "            'num_units_per_layer': hid_feats,\n",
    "            'activation_functions': activation,\n",
    "            'learning_rates': lr, \n",
    "            'batch_sizes': batch_size,\n",
    "            'aggregator_type': agg_type,\n",
    "            'acc': accuracy,\n",
    "            'precision': precision,\n",
    "            'recall': recall,\n",
    "            'details': df,\n",
    "        }\n",
    "        results.append(result)\n",
    "    return results, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "e86c41e9-582e-4ff9-a6f7-d526e08e85a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3fb1c17a297940179a3909b0aaf2c43a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with layers: 2, units per layer: 50, activation: relu, learning rate: 0.001, batch size: 32, aggreagator type: mean\n",
      "Training with layers: 3, units per layer: 50, activation: relu, learning rate: 0.001, batch size: 32, aggreagator type: mean\n",
      "Training with layers: 4, units per layer: 50, activation: relu, learning rate: 0.001, batch size: 32, aggreagator type: mean\n",
      "Training with layers: 5, units per layer: 50, activation: relu, learning rate: 0.001, batch size: 32, aggreagator type: mean\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([{'num_hidden_layers': 2,\n",
       "   'num_units_per_layer': 50,\n",
       "   'activation_functions': <function torch.nn.functional.relu(input: torch.Tensor, inplace: bool = False) -> torch.Tensor>,\n",
       "   'learning_rates': 0.001,\n",
       "   'batch_sizes': 32,\n",
       "   'aggregator_type': 'mean',\n",
       "   'acc': 0.7959,\n",
       "   'precision': 0.7959,\n",
       "   'recall': 0.7959,\n",
       "   'details':     epoch       loss   val_acc      time\n",
       "   0       0  15.905062  0.041005  0.017063\n",
       "   1       1  11.314794  0.175926  0.014814\n",
       "   2       2   8.912500  0.369048  0.024174\n",
       "   3       3   7.652423  0.379630  0.022931\n",
       "   4       4   6.080705  0.382275  0.017010\n",
       "   ..    ...        ...       ...       ...\n",
       "   95     95   0.698524  0.777778  0.015410\n",
       "   96     96   0.695090  0.776455  0.015021\n",
       "   97     97   0.691905  0.779101  0.011401\n",
       "   98     98   0.688601  0.783069  0.017760\n",
       "   99     99   0.685116  0.789683  0.014525\n",
       "   \n",
       "   [100 rows x 4 columns]},\n",
       "  {'num_hidden_layers': 3,\n",
       "   'num_units_per_layer': 50,\n",
       "   'activation_functions': <function torch.nn.functional.relu(input: torch.Tensor, inplace: bool = False) -> torch.Tensor>,\n",
       "   'learning_rates': 0.001,\n",
       "   'batch_sizes': 32,\n",
       "   'aggregator_type': 'mean',\n",
       "   'acc': 0.818705,\n",
       "   'precision': 0.818705,\n",
       "   'recall': 0.818705,\n",
       "   'details':     epoch       loss   val_acc      time\n",
       "   0       0  43.523991  0.019841  0.024324\n",
       "   1       1  36.128269  0.019841  0.022966\n",
       "   2       2  30.112377  0.019841  0.015010\n",
       "   3       3  25.265535  0.019841  0.015125\n",
       "   4       4  20.352184  0.031746  0.017490\n",
       "   ..    ...        ...       ...       ...\n",
       "   95     95   0.654896  0.821429  0.018256\n",
       "   96     96   0.652448  0.821429  0.013993\n",
       "   97     97   0.649391  0.817460  0.013125\n",
       "   98     98   0.645758  0.818783  0.015604\n",
       "   99     99   0.642479  0.816138  0.019396\n",
       "   \n",
       "   [100 rows x 4 columns]},\n",
       "  {'num_hidden_layers': 4,\n",
       "   'num_units_per_layer': 50,\n",
       "   'activation_functions': <function torch.nn.functional.relu(input: torch.Tensor, inplace: bool = False) -> torch.Tensor>,\n",
       "   'learning_rates': 0.001,\n",
       "   'batch_sizes': 32,\n",
       "   'aggregator_type': 'mean',\n",
       "   'acc': 0.820318,\n",
       "   'precision': 0.820318,\n",
       "   'recall': 0.820318,\n",
       "   'details':     epoch       loss   val_acc      time\n",
       "   0       0  12.822831  0.115079  0.033528\n",
       "   1       1  10.811139  0.350529  0.021310\n",
       "   2       2   7.995183  0.349206  0.022840\n",
       "   3       3   4.867923  0.325397  0.021561\n",
       "   4       4   4.392050  0.343915  0.024616\n",
       "   ..    ...        ...       ...       ...\n",
       "   95     95   0.592782  0.798942  0.020909\n",
       "   96     96   0.589099  0.804233  0.025730\n",
       "   97     97   0.585553  0.802910  0.022683\n",
       "   98     98   0.582168  0.804233  0.019874\n",
       "   99     99   0.578646  0.806878  0.021679\n",
       "   \n",
       "   [100 rows x 4 columns]},\n",
       "  {'num_hidden_layers': 5,\n",
       "   'num_units_per_layer': 50,\n",
       "   'activation_functions': <function torch.nn.functional.relu(input: torch.Tensor, inplace: bool = False) -> torch.Tensor>,\n",
       "   'learning_rates': 0.001,\n",
       "   'batch_sizes': 32,\n",
       "   'aggregator_type': 'mean',\n",
       "   'acc': 0.813868,\n",
       "   'precision': 0.813868,\n",
       "   'recall': 0.813868,\n",
       "   'details':     epoch       loss   val_acc      time\n",
       "   0       0  51.642262  0.000000  0.032394\n",
       "   1       1  35.834461  0.019841  0.028509\n",
       "   2       2  27.338758  0.332011  0.028629\n",
       "   3       3  23.930304  0.335979  0.029182\n",
       "   4       4  18.921053  0.354497  0.026041\n",
       "   ..    ...        ...       ...       ...\n",
       "   95     95   0.601924  0.804233  0.023011\n",
       "   96     96   0.598160  0.806878  0.028241\n",
       "   97     97   0.595189  0.809524  0.036633\n",
       "   98     98   0.592269  0.810847  0.039380\n",
       "   99     99   0.588765  0.810847  0.038233\n",
       "   \n",
       "   [100 rows x 4 columns]}],\n",
       " SAGE(\n",
       "   (layers): ModuleList(\n",
       "     (0): SAGEConv(\n",
       "       (feat_drop): Dropout(p=0.0, inplace=False)\n",
       "       (fc_neigh): Linear(in_features=8, out_features=50, bias=False)\n",
       "       (fc_self): Linear(in_features=8, out_features=50, bias=True)\n",
       "     )\n",
       "     (1-4): 4 x SAGEConv(\n",
       "       (feat_drop): Dropout(p=0.0, inplace=False)\n",
       "       (fc_neigh): Linear(in_features=50, out_features=50, bias=False)\n",
       "       (fc_self): Linear(in_features=50, out_features=50, bias=True)\n",
       "     )\n",
       "     (5): SAGEConv(\n",
       "       (feat_drop): Dropout(p=0.0, inplace=False)\n",
       "       (fc_neigh): Linear(in_features=50, out_features=13, bias=False)\n",
       "       (fc_self): Linear(in_features=50, out_features=13, bias=True)\n",
       "     )\n",
       "   )\n",
       " ))"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_hidden_layers = [2, 3, 4, 5]\n",
    "num_units_per_layer = [50]\n",
    "activation_functions = [F.relu]\n",
    "learning_rates = [0.001]\n",
    "batch_sizes = [32]\n",
    "aggregator_type = ['mean']\n",
    "\n",
    "# Create a grid of hyperparameters\n",
    "param_grid = list(itertools.product(num_hidden_layers, num_units_per_layer, activation_functions, learning_rates, batch_sizes, aggregator_type))\n",
    "\n",
    "hidden_layers_results = train_with_grid(param_grid)\n",
    "hidden_layers_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e763a367-9dc8-4a0f-abb9-cf12339539cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "487b8576c0c94508ae16e6234f3dae23",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with layers: 3, units per layer: 25, activation: relu, learning rate: 0.001, batch size: 32, aggreagator type: mean\n",
      "Training with layers: 3, units per layer: 50, activation: relu, learning rate: 0.001, batch size: 32, aggreagator type: mean\n",
      "Training with layers: 3, units per layer: 75, activation: relu, learning rate: 0.001, batch size: 32, aggreagator type: mean\n",
      "Training with layers: 3, units per layer: 100, activation: relu, learning rate: 0.001, batch size: 32, aggreagator type: mean\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([{'num_hidden_layers': 3,\n",
       "   'num_units_per_layer': 25,\n",
       "   'activation_functions': <function torch.nn.functional.relu(input: torch.Tensor, inplace: bool = False) -> torch.Tensor>,\n",
       "   'learning_rates': 0.001,\n",
       "   'batch_sizes': 32,\n",
       "   'aggregator_type': 'mean',\n",
       "   'acc': 0.800507,\n",
       "   'precision': 0.800507,\n",
       "   'recall': 0.800507,\n",
       "   'details':     epoch       loss   val_acc      time\n",
       "   0       0  16.531101  0.037037  0.027119\n",
       "   1       1  14.095226  0.144180  0.026290\n",
       "   2       2  12.199215  0.187831  0.018760\n",
       "   3       3  11.253201  0.292328  0.014049\n",
       "   4       4  10.635205  0.309524  0.010842\n",
       "   ..    ...        ...       ...       ...\n",
       "   95     95   0.814908  0.796296  0.011889\n",
       "   96     96   0.808954  0.800265  0.011298\n",
       "   97     97   0.802853  0.802910  0.011160\n",
       "   98     98   0.796753  0.802910  0.011314\n",
       "   99     99   0.790802  0.802910  0.007514\n",
       "   \n",
       "   [100 rows x 4 columns]},\n",
       "  {'num_hidden_layers': 3,\n",
       "   'num_units_per_layer': 50,\n",
       "   'activation_functions': <function torch.nn.functional.relu(input: torch.Tensor, inplace: bool = False) -> torch.Tensor>,\n",
       "   'learning_rates': 0.001,\n",
       "   'batch_sizes': 32,\n",
       "   'aggregator_type': 'mean',\n",
       "   'acc': 0.830569,\n",
       "   'precision': 0.830569,\n",
       "   'recall': 0.830569,\n",
       "   'details':     epoch       loss   val_acc      time\n",
       "   0       0  14.712915  0.026455  0.015732\n",
       "   1       1   8.515048  0.138889  0.016918\n",
       "   2       2   6.314095  0.325397  0.014426\n",
       "   3       3   4.481659  0.375661  0.016052\n",
       "   4       4   3.385986  0.480159  0.014992\n",
       "   ..    ...        ...       ...       ...\n",
       "   95     95   0.581553  0.829365  0.012954\n",
       "   96     96   0.577054  0.832011  0.012502\n",
       "   97     97   0.572327  0.834656  0.016288\n",
       "   98     98   0.567617  0.834656  0.012281\n",
       "   99     99   0.563112  0.834656  0.014647\n",
       "   \n",
       "   [100 rows x 4 columns]},\n",
       "  {'num_hidden_layers': 3,\n",
       "   'num_units_per_layer': 75,\n",
       "   'activation_functions': <function torch.nn.functional.relu(input: torch.Tensor, inplace: bool = False) -> torch.Tensor>,\n",
       "   'learning_rates': 0.001,\n",
       "   'batch_sizes': 32,\n",
       "   'aggregator_type': 'mean',\n",
       "   'acc': 0.839092,\n",
       "   'precision': 0.839092,\n",
       "   'recall': 0.839092,\n",
       "   'details':     epoch       loss   val_acc      time\n",
       "   0       0  57.715908  0.026455  0.027036\n",
       "   1       1  40.297546  0.023810  0.021325\n",
       "   2       2  31.490662  0.019841  0.026006\n",
       "   3       3  25.133902  0.019841  0.021861\n",
       "   4       4  19.595592  0.019841  0.020433\n",
       "   ..    ...        ...       ...       ...\n",
       "   95     95   0.521923  0.824074  0.033393\n",
       "   96     96   0.517728  0.828042  0.031543\n",
       "   97     97   0.514105  0.822751  0.032158\n",
       "   98     98   0.511005  0.824074  0.031954\n",
       "   99     99   0.507759  0.825397  0.030323\n",
       "   \n",
       "   [100 rows x 4 columns]},\n",
       "  {'num_hidden_layers': 3,\n",
       "   'num_units_per_layer': 100,\n",
       "   'activation_functions': <function torch.nn.functional.relu(input: torch.Tensor, inplace: bool = False) -> torch.Tensor>,\n",
       "   'learning_rates': 0.001,\n",
       "   'batch_sizes': 32,\n",
       "   'aggregator_type': 'mean',\n",
       "   'acc': 0.854296,\n",
       "   'precision': 0.854296,\n",
       "   'recall': 0.854296,\n",
       "   'details':     epoch       loss   val_acc      time\n",
       "   0       0  63.024323  0.027778  0.035247\n",
       "   1       1  45.933842  0.035714  0.030751\n",
       "   2       2  32.297840  0.037037  0.028569\n",
       "   3       3  23.534288  0.039683  0.031662\n",
       "   4       4  13.813547  0.038360  0.027482\n",
       "   ..    ...        ...       ...       ...\n",
       "   95     95   0.462727  0.861111  0.037884\n",
       "   96     96   0.458538  0.866402  0.031752\n",
       "   97     97   0.455922  0.863757  0.038218\n",
       "   98     98   0.452539  0.865079  0.031280\n",
       "   99     99   0.449098  0.865079  0.041275\n",
       "   \n",
       "   [100 rows x 4 columns]}],\n",
       " SAGE(\n",
       "   (layers): ModuleList(\n",
       "     (0): SAGEConv(\n",
       "       (feat_drop): Dropout(p=0.0, inplace=False)\n",
       "       (fc_neigh): Linear(in_features=8, out_features=100, bias=False)\n",
       "       (fc_self): Linear(in_features=8, out_features=100, bias=True)\n",
       "     )\n",
       "     (1-2): 2 x SAGEConv(\n",
       "       (feat_drop): Dropout(p=0.0, inplace=False)\n",
       "       (fc_neigh): Linear(in_features=100, out_features=100, bias=False)\n",
       "       (fc_self): Linear(in_features=100, out_features=100, bias=True)\n",
       "     )\n",
       "     (3): SAGEConv(\n",
       "       (feat_drop): Dropout(p=0.0, inplace=False)\n",
       "       (fc_neigh): Linear(in_features=100, out_features=13, bias=False)\n",
       "       (fc_self): Linear(in_features=100, out_features=13, bias=True)\n",
       "     )\n",
       "   )\n",
       " ))"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_hidden_layers = [3]\n",
    "num_units_per_layer = [25, 50, 75, 100]\n",
    "activation_functions = [F.relu]\n",
    "learning_rates = [0.001]\n",
    "batch_sizes = [32]\n",
    "aggregator_type = ['mean']\n",
    "\n",
    "# Create a grid of hyperparameters\n",
    "param_grid = list(itertools.product(num_hidden_layers, num_units_per_layer, activation_functions, learning_rates, batch_sizes, aggregator_type))\n",
    "\n",
    "num_units_results = train_with_grid(param_grid)\n",
    "num_units_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0d001415-59b6-4a27-ab50-dc81a788ed99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c4b475eff33446b9935a0704ff10d215",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with layers: 3, units per layer: 50, activation: relu, learning rate: 0.001, batch size: 32, aggreagator type: mean\n",
      "Training with layers: 3, units per layer: 50, activation: tanh, learning rate: 0.001, batch size: 32, aggreagator type: mean\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([{'num_hidden_layers': 3,\n",
       "   'num_units_per_layer': 50,\n",
       "   'activation_functions': <function torch.nn.functional.relu(input: torch.Tensor, inplace: bool = False) -> torch.Tensor>,\n",
       "   'learning_rates': 0.001,\n",
       "   'batch_sizes': 32,\n",
       "   'aggregator_type': 'mean',\n",
       "   'acc': 0.828035,\n",
       "   'precision': 0.828035,\n",
       "   'recall': 0.828035,\n",
       "   'details':     epoch       loss   val_acc      time\n",
       "   0       0  29.167978  0.006614  0.034554\n",
       "   1       1  20.938929  0.115079  0.022680\n",
       "   2       2  17.364372  0.361111  0.023863\n",
       "   3       3  15.249525  0.361111  0.021429\n",
       "   4       4  12.758952  0.361111  0.017231\n",
       "   ..    ...        ...       ...       ...\n",
       "   95     95   0.702780  0.818783  0.026884\n",
       "   96     96   0.696395  0.820106  0.018938\n",
       "   97     97   0.692222  0.825397  0.019877\n",
       "   98     98   0.687258  0.826720  0.019253\n",
       "   99     99   0.681391  0.826720  0.019076\n",
       "   \n",
       "   [100 rows x 4 columns]},\n",
       "  {'num_hidden_layers': 3,\n",
       "   'num_units_per_layer': 50,\n",
       "   'activation_functions': <function torch.nn.functional.tanh(input)>,\n",
       "   'learning_rates': 0.001,\n",
       "   'batch_sizes': 32,\n",
       "   'aggregator_type': 'mean',\n",
       "   'acc': 0.814213,\n",
       "   'precision': 0.814213,\n",
       "   'recall': 0.814213,\n",
       "   'details':     epoch      loss   val_acc      time\n",
       "   0       0  2.995456  0.023810  0.020660\n",
       "   1       1  2.399316  0.087302  0.023312\n",
       "   2       2  2.001154  0.268519  0.016610\n",
       "   3       3  1.774291  0.269841  0.017404\n",
       "   4       4  1.651334  0.271164  0.016005\n",
       "   ..    ...       ...       ...       ...\n",
       "   95     95  0.631830  0.801587  0.017827\n",
       "   96     96  0.626886  0.801587  0.014729\n",
       "   97     97  0.621983  0.804233  0.015684\n",
       "   98     98  0.617125  0.805556  0.017185\n",
       "   99     99  0.612321  0.808201  0.018179\n",
       "   \n",
       "   [100 rows x 4 columns]}],\n",
       " SAGE(\n",
       "   (layers): ModuleList(\n",
       "     (0): SAGEConv(\n",
       "       (feat_drop): Dropout(p=0.0, inplace=False)\n",
       "       (fc_neigh): Linear(in_features=8, out_features=50, bias=False)\n",
       "       (fc_self): Linear(in_features=8, out_features=50, bias=True)\n",
       "     )\n",
       "     (1-2): 2 x SAGEConv(\n",
       "       (feat_drop): Dropout(p=0.0, inplace=False)\n",
       "       (fc_neigh): Linear(in_features=50, out_features=50, bias=False)\n",
       "       (fc_self): Linear(in_features=50, out_features=50, bias=True)\n",
       "     )\n",
       "     (3): SAGEConv(\n",
       "       (feat_drop): Dropout(p=0.0, inplace=False)\n",
       "       (fc_neigh): Linear(in_features=50, out_features=13, bias=False)\n",
       "       (fc_self): Linear(in_features=50, out_features=13, bias=True)\n",
       "     )\n",
       "   )\n",
       " ))"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_hidden_layers = [3]\n",
    "num_units_per_layer = [50]\n",
    "activation_functions = [F.relu, F.tanh]\n",
    "learning_rates = [0.001]\n",
    "batch_sizes = [32]\n",
    "aggregator_type = ['mean']\n",
    "\n",
    "# Create a grid of hyperparameters\n",
    "param_grid = list(itertools.product(num_hidden_layers, num_units_per_layer, activation_functions, learning_rates, batch_sizes, aggregator_type))\n",
    "\n",
    "activation_results = train_with_grid(param_grid)\n",
    "activation_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "565b8a7f-6b7a-4251-80d7-6de7a5d1dbdf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d41214aeb9e4b7b919217e83789514e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with layers: 3, units per layer: 50, activation: relu, learning rate: 0.01, batch size: 32, aggreagator type: mean\n",
      "Training with layers: 3, units per layer: 50, activation: relu, learning rate: 0.005, batch size: 32, aggreagator type: mean\n",
      "Training with layers: 3, units per layer: 50, activation: relu, learning rate: 0.001, batch size: 32, aggreagator type: mean\n",
      "Training with layers: 3, units per layer: 50, activation: relu, learning rate: 0.0005, batch size: 32, aggreagator type: mean\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([{'num_hidden_layers': 3,\n",
       "   'num_units_per_layer': 50,\n",
       "   'activation_functions': <function torch.nn.functional.relu(input: torch.Tensor, inplace: bool = False) -> torch.Tensor>,\n",
       "   'learning_rates': 0.01,\n",
       "   'batch_sizes': 32,\n",
       "   'aggregator_type': 'mean',\n",
       "   'acc': 0.938148,\n",
       "   'precision': 0.938148,\n",
       "   'recall': 0.938148,\n",
       "   'details':     epoch       loss   val_acc      time\n",
       "   0       0  33.317741  0.025132  0.032303\n",
       "   1       1  10.015996  0.436508  0.028816\n",
       "   2       2  10.676816  0.339947  0.020405\n",
       "   3       3   6.615351  0.354497  0.015750\n",
       "   4       4   6.717198  0.382275  0.021194\n",
       "   ..    ...        ...       ...       ...\n",
       "   95     95   0.192654  0.937831  0.026063\n",
       "   96     96   0.189751  0.939153  0.025700\n",
       "   97     97   0.187232  0.936508  0.023719\n",
       "   98     98   0.184835  0.937831  0.024848\n",
       "   99     99   0.182431  0.937831  0.025036\n",
       "   \n",
       "   [100 rows x 4 columns]},\n",
       "  {'num_hidden_layers': 3,\n",
       "   'num_units_per_layer': 50,\n",
       "   'activation_functions': <function torch.nn.functional.relu(input: torch.Tensor, inplace: bool = False) -> torch.Tensor>,\n",
       "   'learning_rates': 0.005,\n",
       "   'batch_sizes': 32,\n",
       "   'aggregator_type': 'mean',\n",
       "   'acc': 0.881709,\n",
       "   'precision': 0.881709,\n",
       "   'recall': 0.881709,\n",
       "   'details':     epoch       loss   val_acc      time\n",
       "   0       0  24.621033  0.124339  0.020429\n",
       "   1       1  16.747717  0.386243  0.022826\n",
       "   2       2   6.735690  0.375661  0.024987\n",
       "   3       3  11.817992  0.357143  0.017045\n",
       "   4       4  11.429742  0.370370  0.017244\n",
       "   ..    ...        ...       ...       ...\n",
       "   95     95   0.357309  0.895503  0.016066\n",
       "   96     96   0.354040  0.894180  0.016174\n",
       "   97     97   0.351243  0.894180  0.016205\n",
       "   98     98   0.348641  0.895503  0.012930\n",
       "   99     99   0.345708  0.896825  0.015099\n",
       "   \n",
       "   [100 rows x 4 columns]},\n",
       "  {'num_hidden_layers': 3,\n",
       "   'num_units_per_layer': 50,\n",
       "   'activation_functions': <function torch.nn.functional.relu(input: torch.Tensor, inplace: bool = False) -> torch.Tensor>,\n",
       "   'learning_rates': 0.001,\n",
       "   'batch_sizes': 32,\n",
       "   'aggregator_type': 'mean',\n",
       "   'acc': 0.81237,\n",
       "   'precision': 0.81237,\n",
       "   'recall': 0.81237,\n",
       "   'details':     epoch       loss   val_acc      time\n",
       "   0       0  55.312080  0.026455  0.015051\n",
       "   1       1  47.648014  0.026455  0.017730\n",
       "   2       2  40.425968  0.026455  0.014808\n",
       "   3       3  34.980015  0.026455  0.014545\n",
       "   4       4  30.349541  0.026455  0.014672\n",
       "   ..    ...        ...       ...       ...\n",
       "   95     95   0.785044  0.812169  0.018245\n",
       "   96     96   0.777891  0.816138  0.020088\n",
       "   97     97   0.771313  0.821429  0.017821\n",
       "   98     98   0.764676  0.824074  0.017768\n",
       "   99     99   0.757693  0.824074  0.022489\n",
       "   \n",
       "   [100 rows x 4 columns]},\n",
       "  {'num_hidden_layers': 3,\n",
       "   'num_units_per_layer': 50,\n",
       "   'activation_functions': <function torch.nn.functional.relu(input: torch.Tensor, inplace: bool = False) -> torch.Tensor>,\n",
       "   'learning_rates': 0.0005,\n",
       "   'batch_sizes': 32,\n",
       "   'aggregator_type': 'mean',\n",
       "   'acc': 0.766759,\n",
       "   'precision': 0.766759,\n",
       "   'recall': 0.766759,\n",
       "   'details':     epoch       loss   val_acc      time\n",
       "   0       0  48.241722  0.350529  0.019678\n",
       "   1       1  44.907375  0.350529  0.014550\n",
       "   2       2  42.148876  0.310847  0.014480\n",
       "   3       3  40.197948  0.236772  0.015379\n",
       "   4       4  38.087826  0.222222  0.019255\n",
       "   ..    ...        ...       ...       ...\n",
       "   95     95   0.803921  0.742063  0.020999\n",
       "   96     96   0.800629  0.739418  0.017048\n",
       "   97     97   0.796921  0.739418  0.018804\n",
       "   98     98   0.792488  0.746032  0.017138\n",
       "   99     99   0.787650  0.753968  0.014823\n",
       "   \n",
       "   [100 rows x 4 columns]}],\n",
       " SAGE(\n",
       "   (layers): ModuleList(\n",
       "     (0): SAGEConv(\n",
       "       (feat_drop): Dropout(p=0.0, inplace=False)\n",
       "       (fc_neigh): Linear(in_features=8, out_features=50, bias=False)\n",
       "       (fc_self): Linear(in_features=8, out_features=50, bias=True)\n",
       "     )\n",
       "     (1-2): 2 x SAGEConv(\n",
       "       (feat_drop): Dropout(p=0.0, inplace=False)\n",
       "       (fc_neigh): Linear(in_features=50, out_features=50, bias=False)\n",
       "       (fc_self): Linear(in_features=50, out_features=50, bias=True)\n",
       "     )\n",
       "     (3): SAGEConv(\n",
       "       (feat_drop): Dropout(p=0.0, inplace=False)\n",
       "       (fc_neigh): Linear(in_features=50, out_features=13, bias=False)\n",
       "       (fc_self): Linear(in_features=50, out_features=13, bias=True)\n",
       "     )\n",
       "   )\n",
       " ))"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_hidden_layers = [3]\n",
    "num_units_per_layer = [50]\n",
    "activation_functions = [F.relu]\n",
    "learning_rates = [0.01, 0.005, 0.001, 0.0005]\n",
    "batch_sizes = [32]\n",
    "aggregator_type = ['mean']\n",
    "\n",
    "# Create a grid of hyperparameters\n",
    "param_grid = list(itertools.product(num_hidden_layers, num_units_per_layer, activation_functions, learning_rates, batch_sizes, aggregator_type))\n",
    "\n",
    "lr_results = train_with_grid(param_grid)\n",
    "lr_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d4d25c5f-0307-497b-b9ff-12a74cdbb9a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5977014d9bb343e3b77246117c16213a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with layers: 3, units per layer: 50, activation: relu, learning rate: 0.001, batch size: 16, aggreagator type: mean\n",
      "Training with layers: 3, units per layer: 50, activation: relu, learning rate: 0.001, batch size: 32, aggreagator type: mean\n",
      "Training with layers: 3, units per layer: 50, activation: relu, learning rate: 0.001, batch size: 64, aggreagator type: mean\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([{'num_hidden_layers': 3,\n",
       "   'num_units_per_layer': 50,\n",
       "   'activation_functions': <function torch.nn.functional.relu(input: torch.Tensor, inplace: bool = False) -> torch.Tensor>,\n",
       "   'learning_rates': 0.001,\n",
       "   'batch_sizes': 16,\n",
       "   'aggregator_type': 'mean',\n",
       "   'acc': 0.739346,\n",
       "   'precision': 0.739346,\n",
       "   'recall': 0.739346,\n",
       "   'details':     epoch       loss   val_acc      time\n",
       "   0       0  87.209923  0.026455  0.035996\n",
       "   1       1  78.510414  0.035714  0.032505\n",
       "   2       2  71.699860  0.035714  0.028691\n",
       "   3       3  64.395454  0.038360  0.024818\n",
       "   4       4  56.775005  0.041005  0.022738\n",
       "   ..    ...        ...       ...       ...\n",
       "   95     95   0.827843  0.722222  0.018666\n",
       "   96     96   0.820504  0.730159  0.019255\n",
       "   97     97   0.812420  0.732804  0.016676\n",
       "   98     98   0.808216  0.720899  0.017472\n",
       "   99     99   0.804254  0.720899  0.020113\n",
       "   \n",
       "   [100 rows x 4 columns]},\n",
       "  {'num_hidden_layers': 3,\n",
       "   'num_units_per_layer': 50,\n",
       "   'activation_functions': <function torch.nn.functional.relu(input: torch.Tensor, inplace: bool = False) -> torch.Tensor>,\n",
       "   'learning_rates': 0.001,\n",
       "   'batch_sizes': 32,\n",
       "   'aggregator_type': 'mean',\n",
       "   'acc': 0.769523,\n",
       "   'precision': 0.769523,\n",
       "   'recall': 0.769523,\n",
       "   'details':     epoch       loss   val_acc      time\n",
       "   0       0  55.703316  0.015873  0.023699\n",
       "   1       1  45.931702  0.015873  0.017173\n",
       "   2       2  39.425991  0.015873  0.018402\n",
       "   3       3  34.326263  0.015873  0.017853\n",
       "   4       4  28.881525  0.015873  0.018685\n",
       "   ..    ...        ...       ...       ...\n",
       "   95     95   0.807359  0.724868  0.014774\n",
       "   96     96   0.799938  0.719577  0.014772\n",
       "   97     97   0.793044  0.720899  0.019281\n",
       "   98     98   0.785996  0.727513  0.021285\n",
       "   99     99   0.778666  0.731481  0.018959\n",
       "   \n",
       "   [100 rows x 4 columns]},\n",
       "  {'num_hidden_layers': 3,\n",
       "   'num_units_per_layer': 50,\n",
       "   'activation_functions': <function torch.nn.functional.relu(input: torch.Tensor, inplace: bool = False) -> torch.Tensor>,\n",
       "   'learning_rates': 0.001,\n",
       "   'batch_sizes': 64,\n",
       "   'aggregator_type': 'mean',\n",
       "   'acc': 0.82147,\n",
       "   'precision': 0.82147,\n",
       "   'recall': 0.82147,\n",
       "   'details':     epoch       loss   val_acc      time\n",
       "   0       0  45.275150  0.021164  0.020734\n",
       "   1       1  39.582630  0.195767  0.020738\n",
       "   2       2  37.155769  0.338624  0.019864\n",
       "   3       3  34.546844  0.338624  0.018342\n",
       "   4       4  31.415682  0.337302  0.019126\n",
       "   ..    ...        ...       ...       ...\n",
       "   95     95   0.655030  0.801587  0.014075\n",
       "   96     96   0.646688  0.808201  0.018946\n",
       "   97     97   0.638994  0.809524  0.017462\n",
       "   98     98   0.631919  0.814815  0.015100\n",
       "   99     99   0.624643  0.824074  0.015272\n",
       "   \n",
       "   [100 rows x 4 columns]}],\n",
       " SAGE(\n",
       "   (layers): ModuleList(\n",
       "     (0): SAGEConv(\n",
       "       (feat_drop): Dropout(p=0.0, inplace=False)\n",
       "       (fc_neigh): Linear(in_features=8, out_features=50, bias=False)\n",
       "       (fc_self): Linear(in_features=8, out_features=50, bias=True)\n",
       "     )\n",
       "     (1-2): 2 x SAGEConv(\n",
       "       (feat_drop): Dropout(p=0.0, inplace=False)\n",
       "       (fc_neigh): Linear(in_features=50, out_features=50, bias=False)\n",
       "       (fc_self): Linear(in_features=50, out_features=50, bias=True)\n",
       "     )\n",
       "     (3): SAGEConv(\n",
       "       (feat_drop): Dropout(p=0.0, inplace=False)\n",
       "       (fc_neigh): Linear(in_features=50, out_features=13, bias=False)\n",
       "       (fc_self): Linear(in_features=50, out_features=13, bias=True)\n",
       "     )\n",
       "   )\n",
       " ))"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_hidden_layers = [3]\n",
    "num_units_per_layer = [50]\n",
    "activation_functions = [F.relu]\n",
    "learning_rates = [0.001]\n",
    "batch_sizes = [16, 32, 64]\n",
    "aggregator_type = ['mean']\n",
    "\n",
    "# Create a grid of hyperparameters\n",
    "param_grid = list(itertools.product(num_hidden_layers, num_units_per_layer, activation_functions, learning_rates, batch_sizes, aggregator_type))\n",
    "\n",
    "batch_results = train_with_grid(param_grid)\n",
    "batch_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "23764a4f-445c-48f8-9952-54e75e533a35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "85e8474d66be4d65b221750a1e08fbca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with layers: 3, units per layer: 50, activation: relu, learning rate: 0.001, batch size: 32, aggreagator type: mean\n",
      "Training with layers: 3, units per layer: 50, activation: relu, learning rate: 0.001, batch size: 32, aggreagator type: pool\n",
      "Training with layers: 3, units per layer: 50, activation: relu, learning rate: 0.001, batch size: 32, aggreagator type: lstm\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([{'num_hidden_layers': 3,\n",
       "   'num_units_per_layer': 50,\n",
       "   'activation_functions': <function torch.nn.functional.relu(input: torch.Tensor, inplace: bool = False) -> torch.Tensor>,\n",
       "   'learning_rates': 0.001,\n",
       "   'batch_sizes': 32,\n",
       "   'aggregator_type': 'mean',\n",
       "   'acc': 0.826192,\n",
       "   'precision': 0.826192,\n",
       "   'recall': 0.826192,\n",
       "   'details':     epoch       loss   val_acc      time\n",
       "   0       0  31.819288  0.021164  0.022009\n",
       "   1       1  25.051481  0.030423  0.016078\n",
       "   2       2  18.280645  0.041005  0.014560\n",
       "   3       3  12.709352  0.165344  0.013626\n",
       "   4       4  10.021749  0.298942  0.017126\n",
       "   ..    ...        ...       ...       ...\n",
       "   95     95   0.573344  0.810847  0.020077\n",
       "   96     96   0.569976  0.817460  0.017157\n",
       "   97     97   0.566920  0.816138  0.015732\n",
       "   98     98   0.563653  0.820106  0.017582\n",
       "   99     99   0.560235  0.826720  0.016262\n",
       "   \n",
       "   [100 rows x 4 columns]},\n",
       "  {'num_hidden_layers': 3,\n",
       "   'num_units_per_layer': 50,\n",
       "   'activation_functions': <function torch.nn.functional.relu(input: torch.Tensor, inplace: bool = False) -> torch.Tensor>,\n",
       "   'learning_rates': 0.001,\n",
       "   'batch_sizes': 32,\n",
       "   'aggregator_type': 'pool',\n",
       "   'acc': 0.800276,\n",
       "   'precision': 0.800276,\n",
       "   'recall': 0.800276,\n",
       "   'details':     epoch       loss   val_acc      time\n",
       "   0       0  70.598305  0.019841  0.043460\n",
       "   1       1  57.403454  0.019841  0.037848\n",
       "   2       2  48.884197  0.019841  0.035578\n",
       "   3       3  41.859982  0.019841  0.032102\n",
       "   4       4  36.180035  0.019841  0.028807\n",
       "   ..    ...        ...       ...       ...\n",
       "   95     95   0.703970  0.791005  0.025359\n",
       "   96     96   0.699052  0.797619  0.026390\n",
       "   97     97   0.694351  0.804233  0.025953\n",
       "   98     98   0.689621  0.810847  0.028552\n",
       "   99     99   0.684634  0.812169  0.026207\n",
       "   \n",
       "   [100 rows x 4 columns]},\n",
       "  {'num_hidden_layers': 3,\n",
       "   'num_units_per_layer': 50,\n",
       "   'activation_functions': <function torch.nn.functional.relu(input: torch.Tensor, inplace: bool = False) -> torch.Tensor>,\n",
       "   'learning_rates': 0.001,\n",
       "   'batch_sizes': 32,\n",
       "   'aggregator_type': 'lstm',\n",
       "   'acc': 0.861553,\n",
       "   'precision': 0.861553,\n",
       "   'recall': 0.861553,\n",
       "   'details':     epoch       loss   val_acc      time\n",
       "   0       0  11.011587  0.052910  0.158257\n",
       "   1       1   9.400932  0.052910  0.134210\n",
       "   2       2   8.119941  0.068783  0.131659\n",
       "   3       3   7.206961  0.121693  0.132679\n",
       "   4       4   6.591242  0.206349  0.155880\n",
       "   ..    ...        ...       ...       ...\n",
       "   95     95   0.441608  0.873016  0.183435\n",
       "   96     96   0.439501  0.873016  0.176084\n",
       "   97     97   0.437319  0.874339  0.359641\n",
       "   98     98   0.435372  0.878307  0.157665\n",
       "   99     99   0.433484  0.880952  0.154314\n",
       "   \n",
       "   [100 rows x 4 columns]}],\n",
       " SAGE(\n",
       "   (layers): ModuleList(\n",
       "     (0): SAGEConv(\n",
       "       (feat_drop): Dropout(p=0.0, inplace=False)\n",
       "       (lstm): LSTM(8, 8, batch_first=True)\n",
       "       (fc_neigh): Linear(in_features=8, out_features=50, bias=False)\n",
       "       (fc_self): Linear(in_features=8, out_features=50, bias=True)\n",
       "     )\n",
       "     (1-2): 2 x SAGEConv(\n",
       "       (feat_drop): Dropout(p=0.0, inplace=False)\n",
       "       (lstm): LSTM(50, 50, batch_first=True)\n",
       "       (fc_neigh): Linear(in_features=50, out_features=50, bias=False)\n",
       "       (fc_self): Linear(in_features=50, out_features=50, bias=True)\n",
       "     )\n",
       "     (3): SAGEConv(\n",
       "       (feat_drop): Dropout(p=0.0, inplace=False)\n",
       "       (lstm): LSTM(50, 50, batch_first=True)\n",
       "       (fc_neigh): Linear(in_features=50, out_features=13, bias=False)\n",
       "       (fc_self): Linear(in_features=50, out_features=13, bias=True)\n",
       "     )\n",
       "   )\n",
       " ))"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_hidden_layers = [3]\n",
    "num_units_per_layer = [50]\n",
    "activation_functions = [F.relu]\n",
    "learning_rates = [0.001]\n",
    "batch_sizes = [32]\n",
    "aggregator_type = ['mean', 'pool', 'lstm']\n",
    "\n",
    "# Create a grid of hyperparameters\n",
    "param_grid = list(itertools.product(num_hidden_layers, num_units_per_layer, activation_functions, learning_rates, batch_sizes, aggregator_type))\n",
    "\n",
    "agg_results = train_with_grid(param_grid)\n",
    "agg_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ffaf579e-3fcd-4dfe-8810-f14fe30a7d2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e48f312ea5f48e58612b108fba96f02",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with layers: 4, units per layer: 100, activation: relu, learning rate: 0.01, batch size: 64, aggreagator type: lstm\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'num_hidden_layers': 4,\n",
       "  'num_units_per_layer': 100,\n",
       "  'activation_functions': <function torch.nn.functional.relu(input: torch.Tensor, inplace: bool = False) -> torch.Tensor>,\n",
       "  'learning_rates': 0.01,\n",
       "  'batch_sizes': 64,\n",
       "  'aggregator_type': 'lstm',\n",
       "  'acc': 0.955425,\n",
       "  'precision': 0.955425,\n",
       "  'recall': 0.955425,\n",
       "  'details':     epoch      loss   val_acc      time\n",
       "  0       0  6.476654  0.107143  0.574064\n",
       "  1       1  5.111220  0.653439  0.438891\n",
       "  2       2  5.511761  0.546296  0.511938\n",
       "  3       3  5.938691  0.361111  0.660172\n",
       "  4       4  4.010347  0.726190  0.681041\n",
       "  ..    ...       ...       ...       ...\n",
       "  95     95  0.125232  0.955026  0.689732\n",
       "  96     96  0.125232  0.960317  0.709354\n",
       "  97     97  0.120529  0.957672  0.651969\n",
       "  98     98  0.118559  0.958995  0.874100\n",
       "  99     99  0.119317  0.962963  0.598034\n",
       "  \n",
       "  [100 rows x 4 columns]}]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_hidden_layers = [4]\n",
    "num_units_per_layer = [100]\n",
    "activation_functions = [F.relu]\n",
    "learning_rates = [0.01]\n",
    "batch_sizes = [64]\n",
    "aggregator_type = ['lstm']\n",
    "\n",
    "# Create a grid of hyperparameters\n",
    "param_grid = list(itertools.product(num_hidden_layers, num_units_per_layer, activation_functions, learning_rates, batch_sizes, aggregator_type))\n",
    "\n",
    "fine_results, model = train_with_grid(param_grid)\n",
    "fine_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12ac9ec6-321e-46f6-b154-9e8ef315d36d",
   "metadata": {},
   "outputs": [],
   "source": [
    "fine_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "9d5043eb-f712-4f0e-a26e-0b05bffe1d3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary = DGL.ModelClassifyNodes(model, test_data.dataset)\n",
    "# actual = dictionary['alllabels']\n",
    "actual = []\n",
    "for l in dictionary['alllabels']:\n",
    "    actual.extend(l)\n",
    "    \n",
    "# print(actual)\n",
    "# predicted = dictionary['allpredictions']\n",
    "predicted = []\n",
    "for l in dictionary['allpredictions']:\n",
    "    predicted.extend(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "aacf5277-49f1-4dd6-9a4f-df538c52f07d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 160    0    0    0    0    0    0    0    0    0    0    0    0]\n",
      " [   0  120    0    0    0    0    0    0    0    9    0    0    0]\n",
      " [   0    0  146    0    0   27    0    0    0    0    0    0    0]\n",
      " [   0    0   17   87    0   48    0    0    0    0    0    0    0]\n",
      " [   0    0    0    0  177    0   23    7    1    0    0    0    0]\n",
      " [   0    0   77  113    0  407    0    0    0    0    0    0    0]\n",
      " [   0    0    0    0   10    0  408   27    0    0    0    0    0]\n",
      " [   0    0    0    0   11    0   13  166    0    0    0    0    0]\n",
      " [   0    0    0    0    2    0    0    0  139    0    0    0    0]\n",
      " [   0    0    0    0    0    0    0    0    0  231    0    0    0]\n",
      " [   0    0    0    0    0    0    0    0    2    0  222    0    0]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0 3263    0]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0    0 2769]]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<iframe\n",
       "    scrolling=\"no\"\n",
       "    width=\"970px\"\n",
       "    height=\"520\"\n",
       "    src=\"iframe_figures/figure_43.html\"\n",
       "    frameborder=\"0\"\n",
       "    allowfullscreen\n",
       "></iframe>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cf = DGL.ConfusionMatrix(actual = actual, predicted = predicted)\n",
    "print(cf)\n",
    "fig = Plotly.FigureByConfusionMatrix(cf)\n",
    "Plotly.Show(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "7b4f8fc6-8903-4380-aafa-adeee4253113",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.955425017277125"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categories = set(actual+predicted)\n",
    "categories\n",
    "true_positives = {category: 0 for category in categories}\n",
    "false_positives = {category: 0 for category in categories}\n",
    "false_negatives = {category: 0 for category in categories}\n",
    "n_labels = {category: 0 for category in categories}\n",
    "\n",
    "\n",
    "for i in range(len(predicted)):\n",
    "    if predicted[i] == actual[i]:\n",
    "        true_positives[actual[i]] += 1\n",
    "    else:\n",
    "        false_positives[predicted[i]] += 1\n",
    "\n",
    "for i in range(len(predicted)):\n",
    "    if predicted[i] == actual[i]:\n",
    "        pass\n",
    "    else:\n",
    "        false_negatives[actual[i]] += 1\n",
    "\n",
    "for i in range(len(categories)):\n",
    "    n_labels[i] = true_positives[i] + false_negatives[i]\n",
    "\n",
    "true_positives\n",
    "false_positives\n",
    "\n",
    "total_true_positives = sum(true_positives.values())\n",
    "total_false_positives = sum(false_positives.values())\n",
    "total_true_positives / (total_true_positives + total_false_positives)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "d17bc494-83d6-493b-8b8e-b101ba0113f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "precision for 0: 1.0\n",
      "recall for 0: 1.0\n",
      "---\n",
      "1\n",
      "precision for 1: 0.9302325581395349\n",
      "recall for 1: 1.0\n",
      "---\n",
      "2\n",
      "precision for 2: 0.8439306358381503\n",
      "recall for 2: 0.6083333333333333\n",
      "---\n",
      "3\n",
      "precision for 3: 0.5723684210526315\n",
      "recall for 3: 0.435\n",
      "---\n",
      "4\n",
      "precision for 4: 0.8509615384615384\n",
      "recall for 4: 0.885\n",
      "---\n",
      "5\n",
      "precision for 5: 0.6817420435510888\n",
      "recall for 5: 0.8443983402489627\n",
      "---\n",
      "6\n",
      "precision for 6: 0.9168539325842696\n",
      "recall for 6: 0.918918918918919\n",
      "---\n",
      "7\n",
      "precision for 7: 0.8736842105263158\n",
      "recall for 7: 0.83\n",
      "---\n",
      "8\n",
      "precision for 8: 0.9858156028368794\n",
      "recall for 8: 0.9788732394366197\n",
      "---\n",
      "9\n",
      "precision for 9: 1.0\n",
      "recall for 9: 0.9625\n",
      "---\n",
      "10\n",
      "precision for 10: 0.9910714285714286\n",
      "recall for 10: 1.0\n",
      "---\n",
      "11\n",
      "precision for 11: 1.0\n",
      "recall for 11: 1.0\n",
      "---\n",
      "12\n",
      "precision for 12: 1.0\n",
      "recall for 12: 1.0\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "for c in range(len(categories)):\n",
    "    if (true_positives[c] + false_positives[c]) == 0:\n",
    "        precision = 0\n",
    "    else:\n",
    "        precision = true_positives[c] / (true_positives[c] + false_positives[c])\n",
    "\n",
    "    if (true_positives[c] + false_negatives[c]) == 0:\n",
    "        recall = 0\n",
    "    else:\n",
    "        recall = true_positives[c] / (true_positives[c] + false_negatives[c])\n",
    "    # if (true_positives[c] + n_labels[c]) == 0:\n",
    "    #     accuracy = 0\n",
    "    # else:\n",
    "    #     accuracy = true_positives[c]/ (n_labels[c])\n",
    "    \n",
    "    # print(f\"accuracy for {c}: {accuracy}\")\n",
    "    print(c)\n",
    "    print(f\"precision for {c}: {precision}\")\n",
    "    print(f\"recall for {c}: {recall}\")\n",
    "    print(\"---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf4b60a9-efb9-4011-9ee0-00717cac3cdc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
