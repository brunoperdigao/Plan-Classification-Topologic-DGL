{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "999d413e-7177-4ab5-a81d-883993f9647b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"/home/brunoperdigao/repos/Plan-Classification-Topologic-DGL\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c3936cc9-d0d7-456f-814e-04a29cd96e07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Libraries\n",
    "import time\n",
    "import sklearn\n",
    "import numpy as np\n",
    "np.random.seed(0)\n",
    "import pandas as pd\n",
    "from topologicpy.DGL import DGL\n",
    "from topologicpy.Dictionary import Dictionary\n",
    "from topologicpy.Topology import Topology\n",
    "from topologicpy.Vertex import Vertex\n",
    "from topologicpy.Graph import Graph\n",
    "from topologicpy.Plotly import Plotly\n",
    "import itertools\n",
    "import dgl\n",
    "import torch\n",
    "torch.manual_seed(0)\n",
    "torch.use_deterministic_algorithms(True)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "\n",
    "import random\n",
    "random.seed(0)\n",
    "\n",
    "import dgl.nn as dglnn\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from dgl import save_graphs, load_graphs\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "192d64e0-827f-4047-9d9a-3d5a35d65624",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done saving data into cached files.\n",
      "Dataset(\"GraphDGL\", num_graphs=200, save_path=/home/bruno_perdigao/.dgl/GraphDGL)\n"
     ]
    }
   ],
   "source": [
    "path = \"./data3\"\n",
    "dataset = DGL.DatasetByCSVPath(path, numberOfGraphClasses=0,\n",
    "                           nodeATTRKey='feat', edgeATTRKey='feat',\n",
    "                           nodeOneHotEncode=False, nodeFeaturesCategories=[],\n",
    "                           edgeOneHotEncode=False, edgeFeaturesCategories=[], addSelfLoop=False)\n",
    "print(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "847cf7ab-8a98-4a2f-8424-c30b49643260",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, val_data, test_data = dgl.data.utils.split_dataset(dataset, [0.7, 0.1, 0.2], random_state=101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c17fc4c8-7fc2-4c26-bf00-80bf67916fff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset(\"GraphDGL\", num_graphs=200, save_path=/home/bruno_perdigao/.dgl/GraphDGL)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a3d880f-9d40-41fe-94f6-fe48645343d2",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a248d8dc-cb2b-4814-9f06-3b06742b8d10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Contruct a two-layer GNN model\n",
    "# import dgl.nn as dglnn\n",
    "# import torch.nn as nn\n",
    "# import torch.nn.functional as F\n",
    "# class SAGE(nn.Module):\n",
    "#     def __init__(self, in_feats, hid_feats, out_feats):\n",
    "#         super().__init__()\n",
    "#         self.conv1 = dglnn.SAGEConv(\n",
    "#             in_feats=in_feats, out_feats=hid_feats, aggregator_type='mean')\n",
    "#         self.conv2 = dglnn.SAGEConv(\n",
    "#             in_feats=hid_feats, out_feats=out_feats, aggregator_type='mean')\n",
    "\n",
    "#     def forward(self, graph, inputs):\n",
    "#         # inputs are features of nodes\n",
    "#         h = self.conv1(graph, inputs)\n",
    "#         h = F.relu(h)\n",
    "#         h = self.conv2(graph, h)\n",
    "#         return h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e24c9c9a-3b84-470b-b272-092837f8524b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, graph, features, labels, mask):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        logits = model(graph, features)\n",
    "        logits = logits[mask]\n",
    "        labels = labels[mask]\n",
    "        _, indices = torch.max(logits, dim=1)\n",
    "        correct = torch.sum(indices == labels)\n",
    "        return correct.item() * 1.0 / len(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b70000f9-3fb5-4eda-adec-9197707aebae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # print(len(dataset.graphs))\n",
    "# for i, graph in enumerate(dataset.graphs):\n",
    "#     # print(i)\n",
    "#     node_features = graph.ndata['feat']\n",
    "#     # print(node_features)\n",
    "#     node_labels = graph.ndata['label']\n",
    "#     # print(node_labels)\n",
    "#     train_mask = graph.ndata['train_mask']\n",
    "#     valid_mask = graph.ndata['val_mask']\n",
    "#     test_mask = graph.ndata['test_mask']\n",
    "#     n_features = node_features.shape[1]\n",
    "#     # print(n_features)\n",
    "#     n_labels = int(node_labels.max().item() + 1)\n",
    "#     # print(n_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f162c1f1-a7f9-4534-8819-39e309da5551",
   "metadata": {},
   "source": [
    "# Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "73621f83-2f0a-457b-a8b0-f3fd6fb45e09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# num_hidden_layers = [2, 3, 4, 5]\n",
    "# num_units_per_layer = [25, 50, 100]\n",
    "# activation_functions = [F.relu, F.tanh]\n",
    "# learning_rates = [0.01, 0.001, 0.0005]\n",
    "# batch_sizes = [16, 32, 64]\n",
    "# aggregator_type = ['mean', 'pool', 'lstm']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1cee4d2f-c20f-4ea5-bebf-4f1f3f81e1fc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def evaluate_selected_model(model):\n",
    "    dictionary = DGL.ModelClassifyNodes(model, test_data.dataset)\n",
    "    \n",
    "    actual = []\n",
    "    for l in dictionary['alllabels']:\n",
    "        actual.extend(l)\n",
    "        \n",
    "    predicted = []\n",
    "    for l in dictionary['allpredictions']:\n",
    "        predicted.extend(l)\n",
    "\n",
    "    result = DGL.Accuracy(actual=actual, predicted=predicted)\n",
    "    accuracy = result['accuracy']\n",
    "    precision = DGL.Precision(actual=actual, predicted=predicted)\n",
    "    recall = DGL.Recall(actual=actual, predicted=predicted)\n",
    "   \n",
    "    return accuracy, precision, recall\n",
    "\n",
    "class SAGE(nn.Module):\n",
    "    def __init__(self, in_feats, hid_feats, out_feats, num_layers, activation, agg_type):\n",
    "        super().__init__()\n",
    "        self.layers = nn.ModuleList()\n",
    "        self.activation = activation\n",
    "        \n",
    "        # Create the specified number of hidden layers\n",
    "        self.layers.append(dglnn.SAGEConv(in_feats=in_feats, out_feats=hid_feats, aggregator_type=agg_type))\n",
    "        for _ in range(num_layers - 1):\n",
    "            self.layers.append(dglnn.SAGEConv(in_feats=hid_feats, out_feats=hid_feats, aggregator_type=agg_type))\n",
    "        self.layers.append(dglnn.SAGEConv(in_feats=hid_feats, out_feats=out_feats, aggregator_type=agg_type))\n",
    "\n",
    "    def forward(self, graph, inputs):\n",
    "        h = inputs\n",
    "        for layer in self.layers[:-1]:\n",
    "            h = layer(graph, h)\n",
    "            h = self.activation(h)  # Apply activation function\n",
    "        h = self.layers[-1](graph, h)  # Last layer without activation\n",
    "        return h\n",
    "\n",
    "\n",
    "def train_with_grid(param_grid):\n",
    "    results = []\n",
    "    \n",
    "    # Iterate over all combinations of hyperparameters\n",
    "    for num_layers, hid_feats, activation, lr, batch_size, agg_type in tqdm(param_grid):\n",
    "        print(f\"Training with layers: {num_layers}, units per layer: {hid_feats}, activation: {activation.__name__}, learning rate: {lr}, batch size: {batch_size}, aggreagator type: {agg_type}\")\n",
    "        \n",
    "        # Initialize model and optimizer\n",
    "        n_features = 8\n",
    "        model = SAGE(in_feats=n_features, hid_feats=hid_feats, out_feats=13, num_layers=num_layers, activation=activation, agg_type=agg_type)\n",
    "        opt = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "        \n",
    "        \n",
    "    \n",
    "        # for i, graph in enumerate(dataset.graphs):\n",
    "        all_graph = dgl.batch(dataset.graphs)\n",
    "            \n",
    "        df = pd.DataFrame(columns=['epoch', 'loss', 'val_acc', 'time'])\n",
    "        for epoch in range(100):\n",
    "            start = time.time()        \n",
    "            node_features = all_graph.ndata['feat']\n",
    "            node_labels = all_graph.ndata['label']\n",
    "            train_mask = all_graph.ndata['train_mask']\n",
    "            valid_mask = all_graph.ndata['val_mask']\n",
    "            test_mask = all_graph.ndata['test_mask']\n",
    "            n_features = node_features.shape[1]\n",
    "            n_labels = int(node_labels.max().item() + 1)\n",
    "\n",
    "            model.train()\n",
    "            # forward propagation by using all nodes\n",
    "            logits = model(all_graph, node_features)\n",
    "            # compute loss\n",
    "            loss = F.cross_entropy(logits[train_mask], node_labels[train_mask])\n",
    "            # compute validation accuracy\n",
    "            acc = evaluate(model, all_graph, node_features, node_labels, valid_mask)\n",
    "            # backward propagation\n",
    "            opt.zero_grad()\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "            total_time = time.time() - start\n",
    "            df.loc[len(df)]={\"epoch\": epoch, \"loss\": loss.item(), \"val_acc\": acc, \"time\": total_time}\n",
    "            # print(loss.item())\n",
    "\n",
    "        accuracy, precision, recall = evaluate_selected_model(model)  \n",
    "        result = {\n",
    "            'num_hidden_layers': num_layers,\n",
    "            'num_units_per_layer': hid_feats,\n",
    "            'activation_functions': activation,\n",
    "            'learning_rates': lr, \n",
    "            'batch_sizes': batch_size,\n",
    "            'aggregator_type': agg_type,\n",
    "            'acc': accuracy,\n",
    "            'precision': precision,\n",
    "            'recall': recall,\n",
    "            'details': df,\n",
    "        }\n",
    "        results.append(result)\n",
    "    return results, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e86c41e9-582e-4ff9-a6f7-d526e08e85a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "baef92e3ed254fcf9243e97d9052e140",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with layers: 2, units per layer: 50, activation: relu, learning rate: 0.001, batch size: 32, aggreagator type: mean\n",
      "Training with layers: 3, units per layer: 50, activation: relu, learning rate: 0.001, batch size: 32, aggreagator type: mean\n",
      "Training with layers: 4, units per layer: 50, activation: relu, learning rate: 0.001, batch size: 32, aggreagator type: mean\n",
      "Training with layers: 5, units per layer: 50, activation: relu, learning rate: 0.001, batch size: 32, aggreagator type: mean\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([{'num_hidden_layers': 2,\n",
       "   'num_units_per_layer': 50,\n",
       "   'activation_functions': <function torch.nn.functional.relu(input: torch.Tensor, inplace: bool = False) -> torch.Tensor>,\n",
       "   'learning_rates': 0.001,\n",
       "   'batch_sizes': 32,\n",
       "   'aggregator_type': 'mean',\n",
       "   'acc': 0.766644,\n",
       "   'precision': 0.766644,\n",
       "   'recall': 0.766644,\n",
       "   'details':     epoch       loss   val_acc      time\n",
       "   0       0  59.860317  0.015873  0.031590\n",
       "   1       1  54.706005  0.015873  0.023355\n",
       "   2       2  49.620918  0.015873  0.015324\n",
       "   3       3  44.605789  0.015873  0.015284\n",
       "   4       4  39.651905  0.015873  0.011985\n",
       "   ..    ...        ...       ...       ...\n",
       "   95     95   0.690167  0.767196  0.015713\n",
       "   96     96   0.686648  0.768519  0.011838\n",
       "   97     97   0.682857  0.771164  0.012922\n",
       "   98     98   0.679197  0.769841  0.010443\n",
       "   99     99   0.675901  0.765873  0.010659\n",
       "   \n",
       "   [100 rows x 4 columns]},\n",
       "  {'num_hidden_layers': 3,\n",
       "   'num_units_per_layer': 50,\n",
       "   'activation_functions': <function torch.nn.functional.relu(input: torch.Tensor, inplace: bool = False) -> torch.Tensor>,\n",
       "   'learning_rates': 0.001,\n",
       "   'batch_sizes': 32,\n",
       "   'aggregator_type': 'mean',\n",
       "   'acc': 0.836558,\n",
       "   'precision': 0.836558,\n",
       "   'recall': 0.836558,\n",
       "   'details':     epoch       loss   val_acc      time\n",
       "   0       0  19.571318  0.335979  0.026118\n",
       "   1       1  14.808795  0.345238  0.022642\n",
       "   2       2  10.364704  0.379630  0.018625\n",
       "   3       3   6.442767  0.447090  0.020619\n",
       "   4       4   3.847153  0.317460  0.016717\n",
       "   ..    ...        ...       ...       ...\n",
       "   95     95   0.623612  0.850529  0.013536\n",
       "   96     96   0.618757  0.851852  0.013123\n",
       "   97     97   0.614161  0.850529  0.013359\n",
       "   98     98   0.609619  0.850529  0.013496\n",
       "   99     99   0.605413  0.850529  0.015307\n",
       "   \n",
       "   [100 rows x 4 columns]},\n",
       "  {'num_hidden_layers': 4,\n",
       "   'num_units_per_layer': 50,\n",
       "   'activation_functions': <function torch.nn.functional.relu(input: torch.Tensor, inplace: bool = False) -> torch.Tensor>,\n",
       "   'learning_rates': 0.001,\n",
       "   'batch_sizes': 32,\n",
       "   'aggregator_type': 'mean',\n",
       "   'acc': 0.830684,\n",
       "   'precision': 0.830684,\n",
       "   'recall': 0.830684,\n",
       "   'details':     epoch       loss   val_acc      time\n",
       "   0       0  29.883301  0.080688  0.031300\n",
       "   1       1  19.067497  0.228836  0.024307\n",
       "   2       2  18.240330  0.379630  0.026227\n",
       "   3       3  16.144104  0.379630  0.018965\n",
       "   4       4  13.156349  0.379630  0.022967\n",
       "   ..    ...        ...       ...       ...\n",
       "   95     95   0.628995  0.821429  0.024958\n",
       "   96     96   0.623084  0.821429  0.026618\n",
       "   97     97   0.617083  0.825397  0.023952\n",
       "   98     98   0.611523  0.833333  0.017481\n",
       "   99     99   0.606213  0.830688  0.025339\n",
       "   \n",
       "   [100 rows x 4 columns]},\n",
       "  {'num_hidden_layers': 5,\n",
       "   'num_units_per_layer': 50,\n",
       "   'activation_functions': <function torch.nn.functional.relu(input: torch.Tensor, inplace: bool = False) -> torch.Tensor>,\n",
       "   'learning_rates': 0.001,\n",
       "   'batch_sizes': 32,\n",
       "   'aggregator_type': 'mean',\n",
       "   'acc': 0.828496,\n",
       "   'precision': 0.828496,\n",
       "   'recall': 0.828496,\n",
       "   'details':     epoch       loss   val_acc      time\n",
       "   0       0  40.979488  0.019841  0.033821\n",
       "   1       1  30.292158  0.022487  0.032750\n",
       "   2       2  23.185179  0.025132  0.024651\n",
       "   3       3  16.362696  0.019841  0.025408\n",
       "   4       4  10.438053  0.021164  0.030361\n",
       "   ..    ...        ...       ...       ...\n",
       "   95     95   0.617181  0.833333  0.031785\n",
       "   96     96   0.613217  0.837302  0.027015\n",
       "   97     97   0.609846  0.839947  0.022936\n",
       "   98     98   0.607043  0.838624  0.022199\n",
       "   99     99   0.604114  0.839947  0.021841\n",
       "   \n",
       "   [100 rows x 4 columns]}],\n",
       " SAGE(\n",
       "   (layers): ModuleList(\n",
       "     (0): SAGEConv(\n",
       "       (feat_drop): Dropout(p=0.0, inplace=False)\n",
       "       (fc_neigh): Linear(in_features=8, out_features=50, bias=False)\n",
       "       (fc_self): Linear(in_features=8, out_features=50, bias=True)\n",
       "     )\n",
       "     (1-4): 4 x SAGEConv(\n",
       "       (feat_drop): Dropout(p=0.0, inplace=False)\n",
       "       (fc_neigh): Linear(in_features=50, out_features=50, bias=False)\n",
       "       (fc_self): Linear(in_features=50, out_features=50, bias=True)\n",
       "     )\n",
       "     (5): SAGEConv(\n",
       "       (feat_drop): Dropout(p=0.0, inplace=False)\n",
       "       (fc_neigh): Linear(in_features=50, out_features=13, bias=False)\n",
       "       (fc_self): Linear(in_features=50, out_features=13, bias=True)\n",
       "     )\n",
       "   )\n",
       " ))"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_hidden_layers = [2, 3, 4, 5]\n",
    "num_units_per_layer = [50]\n",
    "activation_functions = [F.relu]\n",
    "learning_rates = [0.001]\n",
    "batch_sizes = [32]\n",
    "aggregator_type = ['mean']\n",
    "\n",
    "# Create a grid of hyperparameters\n",
    "param_grid = list(itertools.product(num_hidden_layers, num_units_per_layer, activation_functions, learning_rates, batch_sizes, aggregator_type))\n",
    "\n",
    "hidden_layers_results = train_with_grid(param_grid)\n",
    "hidden_layers_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e763a367-9dc8-4a0f-abb9-cf12339539cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "615439786c9c47aa82823b35efe47732",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with layers: 3, units per layer: 25, activation: relu, learning rate: 0.001, batch size: 32, aggreagator type: mean\n",
      "Training with layers: 3, units per layer: 50, activation: relu, learning rate: 0.001, batch size: 32, aggreagator type: mean\n",
      "Training with layers: 3, units per layer: 75, activation: relu, learning rate: 0.001, batch size: 32, aggreagator type: mean\n",
      "Training with layers: 3, units per layer: 100, activation: relu, learning rate: 0.001, batch size: 32, aggreagator type: mean\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([{'num_hidden_layers': 3,\n",
       "   'num_units_per_layer': 25,\n",
       "   'activation_functions': <function torch.nn.functional.relu(input: torch.Tensor, inplace: bool = False) -> torch.Tensor>,\n",
       "   'learning_rates': 0.001,\n",
       "   'batch_sizes': 32,\n",
       "   'aggregator_type': 'mean',\n",
       "   'acc': 0.709629,\n",
       "   'precision': 0.709629,\n",
       "   'recall': 0.709629,\n",
       "   'details':     epoch       loss   val_acc      time\n",
       "   0       0  59.457886  0.022487  0.018305\n",
       "   1       1  54.581963  0.022487  0.016561\n",
       "   2       2  49.826000  0.022487  0.022761\n",
       "   3       3  45.246208  0.022487  0.016657\n",
       "   4       4  40.770927  0.022487  0.018160\n",
       "   ..    ...        ...       ...       ...\n",
       "   95     95   1.498372  0.664021  0.018503\n",
       "   96     96   1.461614  0.669312  0.012490\n",
       "   97     97   1.426321  0.674603  0.012116\n",
       "   98     98   1.392486  0.702381  0.013165\n",
       "   99     99   1.361298  0.715608  0.013528\n",
       "   \n",
       "   [100 rows x 4 columns]},\n",
       "  {'num_hidden_layers': 3,\n",
       "   'num_units_per_layer': 50,\n",
       "   'activation_functions': <function torch.nn.functional.relu(input: torch.Tensor, inplace: bool = False) -> torch.Tensor>,\n",
       "   'learning_rates': 0.001,\n",
       "   'batch_sizes': 32,\n",
       "   'aggregator_type': 'mean',\n",
       "   'acc': 0.819742,\n",
       "   'precision': 0.819742,\n",
       "   'recall': 0.819742,\n",
       "   'details':     epoch       loss   val_acc      time\n",
       "   0       0  44.314228  0.002646  0.024595\n",
       "   1       1  34.015102  0.002646  0.021959\n",
       "   2       2  25.348734  0.275132  0.023624\n",
       "   3       3  21.832495  0.341270  0.024632\n",
       "   4       4  18.142187  0.351852  0.022472\n",
       "   ..    ...        ...       ...       ...\n",
       "   95     95   0.670545  0.830688  0.016166\n",
       "   96     96   0.666760  0.832011  0.016870\n",
       "   97     97   0.662586  0.833333  0.013925\n",
       "   98     98   0.658361  0.841270  0.015851\n",
       "   99     99   0.654262  0.839947  0.016899\n",
       "   \n",
       "   [100 rows x 4 columns]},\n",
       "  {'num_hidden_layers': 3,\n",
       "   'num_units_per_layer': 75,\n",
       "   'activation_functions': <function torch.nn.functional.relu(input: torch.Tensor, inplace: bool = False) -> torch.Tensor>,\n",
       "   'learning_rates': 0.001,\n",
       "   'batch_sizes': 32,\n",
       "   'aggregator_type': 'mean',\n",
       "   'acc': 0.823197,\n",
       "   'precision': 0.823197,\n",
       "   'recall': 0.823197,\n",
       "   'details':     epoch       loss   val_acc      time\n",
       "   0       0  57.904194  0.017196  0.038803\n",
       "   1       1  43.216999  0.017196  0.034774\n",
       "   2       2  29.250862  0.017196  0.034161\n",
       "   3       3  19.649170  0.017196  0.026744\n",
       "   4       4  13.058228  0.235450  0.034085\n",
       "   ..    ...        ...       ...       ...\n",
       "   95     95   0.599013  0.835979  0.021665\n",
       "   96     96   0.596149  0.835979  0.021233\n",
       "   97     97   0.593170  0.838624  0.021094\n",
       "   98     98   0.590257  0.837302  0.027041\n",
       "   99     99   0.587831  0.834656  0.036481\n",
       "   \n",
       "   [100 rows x 4 columns]},\n",
       "  {'num_hidden_layers': 3,\n",
       "   'num_units_per_layer': 100,\n",
       "   'activation_functions': <function torch.nn.functional.relu(input: torch.Tensor, inplace: bool = False) -> torch.Tensor>,\n",
       "   'learning_rates': 0.001,\n",
       "   'batch_sizes': 32,\n",
       "   'aggregator_type': 'mean',\n",
       "   'acc': 0.862013,\n",
       "   'precision': 0.862013,\n",
       "   'recall': 0.862013,\n",
       "   'details':     epoch       loss   val_acc      time\n",
       "   0       0  36.851524  0.022487  0.048602\n",
       "   1       1  26.127726  0.022487  0.043019\n",
       "   2       2  15.465561  0.039683  0.044949\n",
       "   3       3   9.276864  0.287037  0.039772\n",
       "   4       4   7.961928  0.387566  0.041914\n",
       "   ..    ...        ...       ...       ...\n",
       "   95     95   0.562879  0.847884  0.040470\n",
       "   96     96   0.557484  0.849206  0.042311\n",
       "   97     97   0.551923  0.854497  0.035235\n",
       "   98     98   0.546845  0.859788  0.038640\n",
       "   99     99   0.542481  0.862434  0.035915\n",
       "   \n",
       "   [100 rows x 4 columns]}],\n",
       " SAGE(\n",
       "   (layers): ModuleList(\n",
       "     (0): SAGEConv(\n",
       "       (feat_drop): Dropout(p=0.0, inplace=False)\n",
       "       (fc_neigh): Linear(in_features=8, out_features=100, bias=False)\n",
       "       (fc_self): Linear(in_features=8, out_features=100, bias=True)\n",
       "     )\n",
       "     (1-2): 2 x SAGEConv(\n",
       "       (feat_drop): Dropout(p=0.0, inplace=False)\n",
       "       (fc_neigh): Linear(in_features=100, out_features=100, bias=False)\n",
       "       (fc_self): Linear(in_features=100, out_features=100, bias=True)\n",
       "     )\n",
       "     (3): SAGEConv(\n",
       "       (feat_drop): Dropout(p=0.0, inplace=False)\n",
       "       (fc_neigh): Linear(in_features=100, out_features=13, bias=False)\n",
       "       (fc_self): Linear(in_features=100, out_features=13, bias=True)\n",
       "     )\n",
       "   )\n",
       " ))"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_hidden_layers = [3]\n",
    "num_units_per_layer = [25, 50, 75, 100]\n",
    "activation_functions = [F.relu]\n",
    "learning_rates = [0.001]\n",
    "batch_sizes = [32]\n",
    "aggregator_type = ['mean']\n",
    "\n",
    "# Create a grid of hyperparameters\n",
    "param_grid = list(itertools.product(num_hidden_layers, num_units_per_layer, activation_functions, learning_rates, batch_sizes, aggregator_type))\n",
    "\n",
    "num_units_results = train_with_grid(param_grid)\n",
    "num_units_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "0d001415-59b6-4a27-ab50-dc81a788ed99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "60981f0524364c1eafb948500b2cc804",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with layers: 3, units per layer: 50, activation: relu, learning rate: 0.001, batch size: 32, aggreagator type: mean\n",
      "Training with layers: 3, units per layer: 50, activation: tanh, learning rate: 0.001, batch size: 32, aggreagator type: mean\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([{'num_hidden_layers': 3,\n",
       "   'num_units_per_layer': 50,\n",
       "   'activation_functions': <function torch.nn.functional.relu(input: torch.Tensor, inplace: bool = False) -> torch.Tensor>,\n",
       "   'learning_rates': 0.001,\n",
       "   'batch_sizes': 32,\n",
       "   'aggregator_type': 'mean',\n",
       "   'acc': 0.775513,\n",
       "   'precision': 0.775513,\n",
       "   'recall': 0.775513,\n",
       "   'details':     epoch       loss   val_acc      time\n",
       "   0       0  24.124041  0.015873  0.030403\n",
       "   1       1  16.623455  0.242063  0.017814\n",
       "   2       2  15.042412  0.312169  0.017081\n",
       "   3       3  12.995396  0.325397  0.019701\n",
       "   4       4  10.572761  0.326720  0.017878\n",
       "   ..    ...        ...       ...       ...\n",
       "   95     95   0.650066  0.771164  0.017964\n",
       "   96     96   0.646522  0.773810  0.016104\n",
       "   97     97   0.643039  0.772487  0.017526\n",
       "   98     98   0.639437  0.773810  0.016236\n",
       "   99     99   0.635766  0.777778  0.022473\n",
       "   \n",
       "   [100 rows x 4 columns]},\n",
       "  {'num_hidden_layers': 3,\n",
       "   'num_units_per_layer': 50,\n",
       "   'activation_functions': <function torch.nn.functional.tanh(input)>,\n",
       "   'learning_rates': 0.001,\n",
       "   'batch_sizes': 32,\n",
       "   'aggregator_type': 'mean',\n",
       "   'acc': 0.831951,\n",
       "   'precision': 0.831951,\n",
       "   'recall': 0.831951,\n",
       "   'details':     epoch      loss   val_acc      time\n",
       "   0       0  3.425103  0.017196  0.031766\n",
       "   1       1  2.865928  0.017196  0.024256\n",
       "   2       2  2.398590  0.018519  0.019319\n",
       "   3       3  2.037517  0.406085  0.017693\n",
       "   4       4  1.780706  0.436508  0.018325\n",
       "   ..    ...       ...       ...       ...\n",
       "   95     95  0.581494  0.830688  0.014915\n",
       "   96     96  0.578418  0.835979  0.015373\n",
       "   97     97  0.575391  0.839947  0.014580\n",
       "   98     98  0.572412  0.843915  0.013363\n",
       "   99     99  0.569482  0.845238  0.017840\n",
       "   \n",
       "   [100 rows x 4 columns]}],\n",
       " SAGE(\n",
       "   (layers): ModuleList(\n",
       "     (0): SAGEConv(\n",
       "       (feat_drop): Dropout(p=0.0, inplace=False)\n",
       "       (fc_neigh): Linear(in_features=8, out_features=50, bias=False)\n",
       "       (fc_self): Linear(in_features=8, out_features=50, bias=True)\n",
       "     )\n",
       "     (1-2): 2 x SAGEConv(\n",
       "       (feat_drop): Dropout(p=0.0, inplace=False)\n",
       "       (fc_neigh): Linear(in_features=50, out_features=50, bias=False)\n",
       "       (fc_self): Linear(in_features=50, out_features=50, bias=True)\n",
       "     )\n",
       "     (3): SAGEConv(\n",
       "       (feat_drop): Dropout(p=0.0, inplace=False)\n",
       "       (fc_neigh): Linear(in_features=50, out_features=13, bias=False)\n",
       "       (fc_self): Linear(in_features=50, out_features=13, bias=True)\n",
       "     )\n",
       "   )\n",
       " ))"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_hidden_layers = [3]\n",
    "num_units_per_layer = [50]\n",
    "activation_functions = [F.relu, F.tanh]\n",
    "learning_rates = [0.001]\n",
    "batch_sizes = [32]\n",
    "aggregator_type = ['mean']\n",
    "\n",
    "# Create a grid of hyperparameters\n",
    "param_grid = list(itertools.product(num_hidden_layers, num_units_per_layer, activation_functions, learning_rates, batch_sizes, aggregator_type))\n",
    "\n",
    "activation_results = train_with_grid(param_grid)\n",
    "activation_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "565b8a7f-6b7a-4251-80d7-6de7a5d1dbdf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "87750635c1c7433aa6dceab001a2971a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with layers: 3, units per layer: 50, activation: relu, learning rate: 0.01, batch size: 32, aggreagator type: mean\n",
      "Training with layers: 3, units per layer: 50, activation: relu, learning rate: 0.005, batch size: 32, aggreagator type: mean\n",
      "Training with layers: 3, units per layer: 50, activation: relu, learning rate: 0.001, batch size: 32, aggreagator type: mean\n",
      "Training with layers: 3, units per layer: 50, activation: relu, learning rate: 0.0005, batch size: 32, aggreagator type: mean\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([{'num_hidden_layers': 3,\n",
       "   'num_units_per_layer': 50,\n",
       "   'activation_functions': <function torch.nn.functional.relu(input: torch.Tensor, inplace: bool = False) -> torch.Tensor>,\n",
       "   'learning_rates': 0.01,\n",
       "   'batch_sizes': 32,\n",
       "   'aggregator_type': 'mean',\n",
       "   'acc': 0.906128,\n",
       "   'precision': 0.906128,\n",
       "   'recall': 0.906128,\n",
       "   'details':     epoch       loss   val_acc      time\n",
       "   0       0  87.685829  0.022487  0.032089\n",
       "   1       1  18.355539  0.326720  0.025683\n",
       "   2       2   8.858552  0.365079  0.020585\n",
       "   3       3   8.592385  0.351852  0.023103\n",
       "   4       4   6.233907  0.370370  0.025810\n",
       "   ..    ...        ...       ...       ...\n",
       "   95     95   0.269638  0.915344  0.019177\n",
       "   96     96   0.267917  0.914021  0.023957\n",
       "   97     97   0.266050  0.914021  0.018580\n",
       "   98     98   0.262147  0.915344  0.014452\n",
       "   99     99   0.260582  0.919312  0.015250\n",
       "   \n",
       "   [100 rows x 4 columns]},\n",
       "  {'num_hidden_layers': 3,\n",
       "   'num_units_per_layer': 50,\n",
       "   'activation_functions': <function torch.nn.functional.relu(input: torch.Tensor, inplace: bool = False) -> torch.Tensor>,\n",
       "   'learning_rates': 0.005,\n",
       "   'batch_sizes': 32,\n",
       "   'aggregator_type': 'mean',\n",
       "   'acc': 0.884704,\n",
       "   'precision': 0.884704,\n",
       "   'recall': 0.884704,\n",
       "   'details':     epoch       loss   val_acc      time\n",
       "   0       0  54.363022  0.046296  0.018626\n",
       "   1       1  30.881811  0.285714  0.015569\n",
       "   2       2  20.233599  0.321429  0.014427\n",
       "   3       3  10.115120  0.218254  0.014994\n",
       "   4       4   6.355668  0.021164  0.015496\n",
       "   ..    ...        ...       ...       ...\n",
       "   95     95   0.383263  0.882275  0.016442\n",
       "   96     96   0.373052  0.888889  0.016560\n",
       "   97     97   0.372151  0.898148  0.016052\n",
       "   98     98   0.369385  0.898148  0.012612\n",
       "   99     99   0.361340  0.896825  0.013521\n",
       "   \n",
       "   [100 rows x 4 columns]},\n",
       "  {'num_hidden_layers': 3,\n",
       "   'num_units_per_layer': 50,\n",
       "   'activation_functions': <function torch.nn.functional.relu(input: torch.Tensor, inplace: bool = False) -> torch.Tensor>,\n",
       "   'learning_rates': 0.001,\n",
       "   'batch_sizes': 32,\n",
       "   'aggregator_type': 'mean',\n",
       "   'acc': 0.764801,\n",
       "   'precision': 0.764801,\n",
       "   'recall': 0.764801,\n",
       "   'details':     epoch       loss   val_acc      time\n",
       "   0       0  66.984856  0.351852  0.054076\n",
       "   1       1  58.742138  0.351852  0.025659\n",
       "   2       2  51.052864  0.351852  0.031019\n",
       "   3       3  43.691612  0.347884  0.018629\n",
       "   4       4  36.541092  0.347884  0.014575\n",
       "   ..    ...        ...       ...       ...\n",
       "   95     95   0.872980  0.756614  0.013519\n",
       "   96     96   0.863332  0.755291  0.013807\n",
       "   97     97   0.855088  0.756614  0.013402\n",
       "   98     98   0.848125  0.760582  0.013060\n",
       "   99     99   0.843238  0.763228  0.013068\n",
       "   \n",
       "   [100 rows x 4 columns]},\n",
       "  {'num_hidden_layers': 3,\n",
       "   'num_units_per_layer': 50,\n",
       "   'activation_functions': <function torch.nn.functional.relu(input: torch.Tensor, inplace: bool = False) -> torch.Tensor>,\n",
       "   'learning_rates': 0.0005,\n",
       "   'batch_sizes': 32,\n",
       "   'aggregator_type': 'mean',\n",
       "   'acc': 0.699378,\n",
       "   'precision': 0.699378,\n",
       "   'recall': 0.699378,\n",
       "   'details':     epoch       loss   val_acc      time\n",
       "   0       0  72.164070  0.052910  0.020805\n",
       "   1       1  66.836983  0.052910  0.021078\n",
       "   2       2  61.660984  0.052910  0.015425\n",
       "   3       3  56.647812  0.052910  0.013535\n",
       "   4       4  51.801327  0.052910  0.021619\n",
       "   ..    ...        ...       ...       ...\n",
       "   95     95   1.087594  0.701058  0.031433\n",
       "   96     96   1.077419  0.694444  0.026244\n",
       "   97     97   1.066636  0.683862  0.027256\n",
       "   98     98   1.057365  0.687831  0.020734\n",
       "   99     99   1.050452  0.687831  0.017467\n",
       "   \n",
       "   [100 rows x 4 columns]}],\n",
       " SAGE(\n",
       "   (layers): ModuleList(\n",
       "     (0): SAGEConv(\n",
       "       (feat_drop): Dropout(p=0.0, inplace=False)\n",
       "       (fc_neigh): Linear(in_features=8, out_features=50, bias=False)\n",
       "       (fc_self): Linear(in_features=8, out_features=50, bias=True)\n",
       "     )\n",
       "     (1-2): 2 x SAGEConv(\n",
       "       (feat_drop): Dropout(p=0.0, inplace=False)\n",
       "       (fc_neigh): Linear(in_features=50, out_features=50, bias=False)\n",
       "       (fc_self): Linear(in_features=50, out_features=50, bias=True)\n",
       "     )\n",
       "     (3): SAGEConv(\n",
       "       (feat_drop): Dropout(p=0.0, inplace=False)\n",
       "       (fc_neigh): Linear(in_features=50, out_features=13, bias=False)\n",
       "       (fc_self): Linear(in_features=50, out_features=13, bias=True)\n",
       "     )\n",
       "   )\n",
       " ))"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_hidden_layers = [3]\n",
    "num_units_per_layer = [50]\n",
    "activation_functions = [F.relu]\n",
    "learning_rates = [0.01, 0.005, 0.001, 0.0005]\n",
    "batch_sizes = [32]\n",
    "aggregator_type = ['mean']\n",
    "\n",
    "# Create a grid of hyperparameters\n",
    "param_grid = list(itertools.product(num_hidden_layers, num_units_per_layer, activation_functions, learning_rates, batch_sizes, aggregator_type))\n",
    "\n",
    "lr_results = train_with_grid(param_grid)\n",
    "lr_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d4d25c5f-0307-497b-b9ff-12a74cdbb9a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dda7211218394bfbbe4b2139f25447b2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with layers: 3, units per layer: 50, activation: relu, learning rate: 0.001, batch size: 16, aggreagator type: mean\n",
      "Training with layers: 3, units per layer: 50, activation: relu, learning rate: 0.001, batch size: 32, aggreagator type: mean\n",
      "Training with layers: 3, units per layer: 50, activation: relu, learning rate: 0.001, batch size: 64, aggreagator type: mean\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([{'num_hidden_layers': 3,\n",
       "   'num_units_per_layer': 50,\n",
       "   'activation_functions': <function torch.nn.functional.relu(input: torch.Tensor, inplace: bool = False) -> torch.Tensor>,\n",
       "   'learning_rates': 0.001,\n",
       "   'batch_sizes': 16,\n",
       "   'aggregator_type': 'mean',\n",
       "   'acc': 0.782423,\n",
       "   'precision': 0.782423,\n",
       "   'recall': 0.782423,\n",
       "   'details':     epoch       loss   val_acc      time\n",
       "   0       0  42.408524  0.000000  0.034891\n",
       "   1       1  28.628466  0.000000  0.023886\n",
       "   2       2  15.220925  0.064815  0.018217\n",
       "   3       3  10.414610  0.363757  0.016327\n",
       "   4       4   9.627637  0.318783  0.018147\n",
       "   ..    ...        ...       ...       ...\n",
       "   95     95   0.733870  0.785714  0.013995\n",
       "   96     96   0.728984  0.784392  0.015428\n",
       "   97     97   0.724050  0.787037  0.014964\n",
       "   98     98   0.718859  0.783069  0.017076\n",
       "   99     99   0.713398  0.781746  0.025292\n",
       "   \n",
       "   [100 rows x 4 columns]},\n",
       "  {'num_hidden_layers': 3,\n",
       "   'num_units_per_layer': 50,\n",
       "   'activation_functions': <function torch.nn.functional.relu(input: torch.Tensor, inplace: bool = False) -> torch.Tensor>,\n",
       "   'learning_rates': 0.001,\n",
       "   'batch_sizes': 32,\n",
       "   'aggregator_type': 'mean',\n",
       "   'acc': 0.778047,\n",
       "   'precision': 0.778047,\n",
       "   'recall': 0.778047,\n",
       "   'details':     epoch       loss   val_acc      time\n",
       "   0       0  31.808765  0.179894  0.022502\n",
       "   1       1  28.474213  0.357143  0.019092\n",
       "   2       2  24.393167  0.272487  0.014663\n",
       "   3       3  20.717932  0.095238  0.013803\n",
       "   4       4  17.457983  0.047619  0.013491\n",
       "   ..    ...        ...       ...       ...\n",
       "   95     95   0.719477  0.789683  0.017870\n",
       "   96     96   0.714193  0.781746  0.018493\n",
       "   97     97   0.707286  0.779101  0.020640\n",
       "   98     98   0.702366  0.784392  0.024892\n",
       "   99     99   0.697677  0.785714  0.022433\n",
       "   \n",
       "   [100 rows x 4 columns]},\n",
       "  {'num_hidden_layers': 3,\n",
       "   'num_units_per_layer': 50,\n",
       "   'activation_functions': <function torch.nn.functional.relu(input: torch.Tensor, inplace: bool = False) -> torch.Tensor>,\n",
       "   'learning_rates': 0.001,\n",
       "   'batch_sizes': 64,\n",
       "   'aggregator_type': 'mean',\n",
       "   'acc': 0.838401,\n",
       "   'precision': 0.838401,\n",
       "   'recall': 0.838401,\n",
       "   'details':     epoch       loss   val_acc      time\n",
       "   0       0  12.886629  0.288360  0.021855\n",
       "   1       1  10.157024  0.369048  0.019750\n",
       "   2       2   7.276868  0.350529  0.019720\n",
       "   3       3   5.096320  0.261905  0.017889\n",
       "   4       4   5.060680  0.425926  0.018798\n",
       "   ..    ...        ...       ...       ...\n",
       "   95     95   0.529586  0.841270  0.015365\n",
       "   96     96   0.526704  0.841270  0.015456\n",
       "   97     97   0.524140  0.838624  0.013457\n",
       "   98     98   0.521697  0.835979  0.013156\n",
       "   99     99   0.519131  0.839947  0.016037\n",
       "   \n",
       "   [100 rows x 4 columns]}],\n",
       " SAGE(\n",
       "   (layers): ModuleList(\n",
       "     (0): SAGEConv(\n",
       "       (feat_drop): Dropout(p=0.0, inplace=False)\n",
       "       (fc_neigh): Linear(in_features=8, out_features=50, bias=False)\n",
       "       (fc_self): Linear(in_features=8, out_features=50, bias=True)\n",
       "     )\n",
       "     (1-2): 2 x SAGEConv(\n",
       "       (feat_drop): Dropout(p=0.0, inplace=False)\n",
       "       (fc_neigh): Linear(in_features=50, out_features=50, bias=False)\n",
       "       (fc_self): Linear(in_features=50, out_features=50, bias=True)\n",
       "     )\n",
       "     (3): SAGEConv(\n",
       "       (feat_drop): Dropout(p=0.0, inplace=False)\n",
       "       (fc_neigh): Linear(in_features=50, out_features=13, bias=False)\n",
       "       (fc_self): Linear(in_features=50, out_features=13, bias=True)\n",
       "     )\n",
       "   )\n",
       " ))"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_hidden_layers = [3]\n",
    "num_units_per_layer = [50]\n",
    "activation_functions = [F.relu]\n",
    "learning_rates = [0.001]\n",
    "batch_sizes = [16, 32, 64]\n",
    "aggregator_type = ['mean']\n",
    "\n",
    "# Create a grid of hyperparameters\n",
    "param_grid = list(itertools.product(num_hidden_layers, num_units_per_layer, activation_functions, learning_rates, batch_sizes, aggregator_type))\n",
    "\n",
    "batch_results = train_with_grid(param_grid)\n",
    "batch_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "23764a4f-445c-48f8-9952-54e75e533a35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "27ea2588bbfa4090be917ff87c8a68a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with layers: 3, units per layer: 50, activation: relu, learning rate: 0.001, batch size: 32, aggreagator type: mean\n",
      "Training with layers: 3, units per layer: 50, activation: relu, learning rate: 0.001, batch size: 32, aggreagator type: pool\n",
      "Training with layers: 3, units per layer: 50, activation: relu, learning rate: 0.001, batch size: 32, aggreagator type: lstm\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([{'num_hidden_layers': 3,\n",
       "   'num_units_per_layer': 50,\n",
       "   'activation_functions': <function torch.nn.functional.relu(input: torch.Tensor, inplace: bool = False) -> torch.Tensor>,\n",
       "   'learning_rates': 0.001,\n",
       "   'batch_sizes': 32,\n",
       "   'aggregator_type': 'mean',\n",
       "   'acc': 0.837825,\n",
       "   'precision': 0.837825,\n",
       "   'recall': 0.837825,\n",
       "   'details':     epoch       loss   val_acc      time\n",
       "   0       0  38.343391  0.017196  0.029200\n",
       "   1       1  29.802776  0.017196  0.023518\n",
       "   2       2  22.071142  0.158730  0.021741\n",
       "   3       3  19.500887  0.244709  0.017494\n",
       "   4       4  17.384188  0.265873  0.021339\n",
       "   ..    ...        ...       ...       ...\n",
       "   95     95   0.647309  0.841270  0.017681\n",
       "   96     96   0.642519  0.839947  0.015521\n",
       "   97     97   0.637861  0.845238  0.014718\n",
       "   98     98   0.633823  0.850529  0.014959\n",
       "   99     99   0.630021  0.851852  0.013720\n",
       "   \n",
       "   [100 rows x 4 columns]},\n",
       "  {'num_hidden_layers': 3,\n",
       "   'num_units_per_layer': 50,\n",
       "   'activation_functions': <function torch.nn.functional.relu(input: torch.Tensor, inplace: bool = False) -> torch.Tensor>,\n",
       "   'learning_rates': 0.001,\n",
       "   'batch_sizes': 32,\n",
       "   'aggregator_type': 'pool',\n",
       "   'acc': 0.813177,\n",
       "   'precision': 0.813177,\n",
       "   'recall': 0.813177,\n",
       "   'details':     epoch       loss   val_acc      time\n",
       "   0       0  42.453983  0.076720  0.051990\n",
       "   1       1  29.692911  0.093915  0.033707\n",
       "   2       2  23.165739  0.349206  0.035032\n",
       "   3       3  19.194532  0.398148  0.029742\n",
       "   4       4  14.489243  0.410053  0.028342\n",
       "   ..    ...        ...       ...       ...\n",
       "   95     95   0.654072  0.808201  0.032211\n",
       "   96     96   0.650935  0.812169  0.030235\n",
       "   97     97   0.647157  0.817460  0.027068\n",
       "   98     98   0.642160  0.816138  0.032882\n",
       "   99     99   0.636880  0.818783  0.029862\n",
       "   \n",
       "   [100 rows x 4 columns]},\n",
       "  {'num_hidden_layers': 3,\n",
       "   'num_units_per_layer': 50,\n",
       "   'activation_functions': <function torch.nn.functional.relu(input: torch.Tensor, inplace: bool = False) -> torch.Tensor>,\n",
       "   'learning_rates': 0.001,\n",
       "   'batch_sizes': 32,\n",
       "   'aggregator_type': 'lstm',\n",
       "   'acc': 0.829302,\n",
       "   'precision': 0.829302,\n",
       "   'recall': 0.829302,\n",
       "   'details':     epoch       loss   val_acc      time\n",
       "   0       0  15.894565  0.033069  0.300234\n",
       "   1       1  13.187600  0.134921  0.188106\n",
       "   2       2  11.009817  0.206349  0.188272\n",
       "   3       3   9.918094  0.380952  0.176922\n",
       "   4       4   8.863814  0.384921  0.142147\n",
       "   ..    ...        ...       ...       ...\n",
       "   95     95   0.523845  0.824074  0.156859\n",
       "   96     96   0.521527  0.828042  0.165919\n",
       "   97     97   0.519172  0.829365  0.247029\n",
       "   98     98   0.516890  0.833333  0.166646\n",
       "   99     99   0.514729  0.835979  0.175737\n",
       "   \n",
       "   [100 rows x 4 columns]}],\n",
       " SAGE(\n",
       "   (layers): ModuleList(\n",
       "     (0): SAGEConv(\n",
       "       (feat_drop): Dropout(p=0.0, inplace=False)\n",
       "       (lstm): LSTM(8, 8, batch_first=True)\n",
       "       (fc_neigh): Linear(in_features=8, out_features=50, bias=False)\n",
       "       (fc_self): Linear(in_features=8, out_features=50, bias=True)\n",
       "     )\n",
       "     (1-2): 2 x SAGEConv(\n",
       "       (feat_drop): Dropout(p=0.0, inplace=False)\n",
       "       (lstm): LSTM(50, 50, batch_first=True)\n",
       "       (fc_neigh): Linear(in_features=50, out_features=50, bias=False)\n",
       "       (fc_self): Linear(in_features=50, out_features=50, bias=True)\n",
       "     )\n",
       "     (3): SAGEConv(\n",
       "       (feat_drop): Dropout(p=0.0, inplace=False)\n",
       "       (lstm): LSTM(50, 50, batch_first=True)\n",
       "       (fc_neigh): Linear(in_features=50, out_features=13, bias=False)\n",
       "       (fc_self): Linear(in_features=50, out_features=13, bias=True)\n",
       "     )\n",
       "   )\n",
       " ))"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_hidden_layers = [3]\n",
    "num_units_per_layer = [50]\n",
    "activation_functions = [F.relu]\n",
    "learning_rates = [0.001]\n",
    "batch_sizes = [32]\n",
    "aggregator_type = ['mean', 'pool', 'lstm']\n",
    "\n",
    "# Create a grid of hyperparameters\n",
    "param_grid = list(itertools.product(num_hidden_layers, num_units_per_layer, activation_functions, learning_rates, batch_sizes, aggregator_type))\n",
    "\n",
    "agg_results = train_with_grid(param_grid)\n",
    "agg_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "ffaf579e-3fcd-4dfe-8810-f14fe30a7d2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b68fe52aac74859a84d71421fca6faa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with layers: 3, units per layer: 100, activation: tanh, learning rate: 0.01, batch size: 64, aggreagator type: mean\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'num_hidden_layers': 3,\n",
       "  'num_units_per_layer': 100,\n",
       "  'activation_functions': <function torch.nn.functional.tanh(input)>,\n",
       "  'learning_rates': 0.01,\n",
       "  'batch_sizes': 64,\n",
       "  'aggregator_type': 'mean',\n",
       "  'acc': 0.958765,\n",
       "  'precision': 0.958765,\n",
       "  'recall': 0.958765,\n",
       "  'details':     epoch      loss   val_acc      time\n",
       "  0       0  4.020436  0.038360  0.052055\n",
       "  1       1  1.293679  0.396825  0.031320\n",
       "  2       2  3.569330  0.376984  0.030866\n",
       "  3       3  1.366555  0.433862  0.032971\n",
       "  4       4  1.157817  0.466931  0.038070\n",
       "  ..    ...       ...       ...       ...\n",
       "  95     95  0.140882  0.964286  0.034497\n",
       "  96     96  0.139538  0.961640  0.036463\n",
       "  97     97  0.138030  0.966931  0.037895\n",
       "  98     98  0.136848  0.961640  0.032361\n",
       "  99     99  0.135836  0.961640  0.031947\n",
       "  \n",
       "  [100 rows x 4 columns]}]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_hidden_layers = [3]\n",
    "num_units_per_layer = [100]\n",
    "activation_functions = [F.tanh]\n",
    "learning_rates = [0.01]\n",
    "batch_sizes = [64]\n",
    "aggregator_type = ['mean']\n",
    "\n",
    "# Create a grid of hyperparameters\n",
    "param_grid = list(itertools.product(num_hidden_layers, num_units_per_layer, activation_functions, learning_rates, batch_sizes, aggregator_type))\n",
    "\n",
    "fine_results, model = train_with_grid(param_grid)\n",
    "fine_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "9d5043eb-f712-4f0e-a26e-0b05bffe1d3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary = DGL.ModelClassifyNodes(model, test_data.dataset)\n",
    "actual = []\n",
    "for l in dictionary['alllabels']:\n",
    "    actual.extend(l)\n",
    "\n",
    "predicted = []\n",
    "for l in dictionary['allpredictions']:\n",
    "    predicted.extend(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "aacf5277-49f1-4dd6-9a4f-df538c52f07d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 160    0    0    0    0    0    0    0    0    0    0    0    0]\n",
      " [   0  120    0    0    0    0    0    0    0    2    0    0    0]\n",
      " [   0    0  161    0    0   31    0    0    0    0    0    0    0]\n",
      " [   0    0    0   76    0   34    0    0    0    0    0    0    0]\n",
      " [   0    0    0    0  183    0    2    0    4    0    0    0    0]\n",
      " [   0    0   79  124    0  417    0    0    0    0    0    0    0]\n",
      " [   0    0    0    0   17    0  428   48    0    0    0    0    0]\n",
      " [   0    0    0    0    0    0   14  149    0    0    0    0    0]\n",
      " [   0    0    0    0    0    0    0    0  138    0    0    0    0]\n",
      " [   0    0    0    0    0    0    0    0    0  238    0    0    0]\n",
      " [   0    0    0    0    0    0    0    3    0    0  222    0    0]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0 3263    0]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0    0 2769]]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<iframe\n",
       "    scrolling=\"no\"\n",
       "    width=\"970px\"\n",
       "    height=\"520\"\n",
       "    src=\"iframe_figures/figure_54.html\"\n",
       "    frameborder=\"0\"\n",
       "    allowfullscreen\n",
       "></iframe>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cf = DGL.ConfusionMatrix(actual = actual, predicted = predicted)\n",
    "print(cf)\n",
    "fig = Plotly.FigureByConfusionMatrix(cf)\n",
    "Plotly.Show(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "7b4f8fc6-8903-4380-aafa-adeee4253113",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.958765261460493"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categories = set(actual+predicted)\n",
    "categories\n",
    "true_positives = {category: 0 for category in categories}\n",
    "false_positives = {category: 0 for category in categories}\n",
    "false_negatives = {category: 0 for category in categories}\n",
    "n_labels = {category: 0 for category in categories}\n",
    "\n",
    "\n",
    "for i in range(len(predicted)):\n",
    "    if predicted[i] == actual[i]:\n",
    "        true_positives[actual[i]] += 1\n",
    "    else:\n",
    "        false_positives[predicted[i]] += 1\n",
    "\n",
    "for i in range(len(predicted)):\n",
    "    if predicted[i] == actual[i]:\n",
    "        pass\n",
    "    else:\n",
    "        false_negatives[actual[i]] += 1\n",
    "\n",
    "for i in range(len(categories)):\n",
    "    n_labels[i] = true_positives[i] + false_negatives[i]\n",
    "\n",
    "true_positives\n",
    "false_positives\n",
    "\n",
    "total_true_positives = sum(true_positives.values())\n",
    "total_false_positives = sum(false_positives.values())\n",
    "total_true_positives / (total_true_positives + total_false_positives)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "d17bc494-83d6-493b-8b8e-b101ba0113f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "precision for 0: 1.0\n",
      "recall for 0: 1.0\n",
      "---\n",
      "1\n",
      "precision for 1: 0.9836065573770492\n",
      "recall for 1: 1.0\n",
      "---\n",
      "2\n",
      "precision for 2: 0.8385416666666666\n",
      "recall for 2: 0.6708333333333333\n",
      "---\n",
      "3\n",
      "precision for 3: 0.6909090909090909\n",
      "recall for 3: 0.38\n",
      "---\n",
      "4\n",
      "precision for 4: 0.9682539682539683\n",
      "recall for 4: 0.915\n",
      "---\n",
      "5\n",
      "precision for 5: 0.6725806451612903\n",
      "recall for 5: 0.8651452282157677\n",
      "---\n",
      "6\n",
      "precision for 6: 0.8681541582150102\n",
      "recall for 6: 0.963963963963964\n",
      "---\n",
      "7\n",
      "precision for 7: 0.9141104294478528\n",
      "recall for 7: 0.745\n",
      "---\n",
      "8\n",
      "precision for 8: 1.0\n",
      "recall for 8: 0.971830985915493\n",
      "---\n",
      "9\n",
      "precision for 9: 1.0\n",
      "recall for 9: 0.9916666666666667\n",
      "---\n",
      "10\n",
      "precision for 10: 0.9866666666666667\n",
      "recall for 10: 1.0\n",
      "---\n",
      "11\n",
      "precision for 11: 1.0\n",
      "recall for 11: 1.0\n",
      "---\n",
      "12\n",
      "precision for 12: 1.0\n",
      "recall for 12: 1.0\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "for c in range(len(categories)):\n",
    "    if (true_positives[c] + false_positives[c]) == 0:\n",
    "        precision = 0\n",
    "    else:\n",
    "        precision = true_positives[c] / (true_positives[c] + false_positives[c])\n",
    "\n",
    "    if (true_positives[c] + false_negatives[c]) == 0:\n",
    "        recall = 0\n",
    "    else:\n",
    "        recall = true_positives[c] / (true_positives[c] + false_negatives[c])\n",
    "    # if (true_positives[c] + n_labels[c]) == 0:\n",
    "    #     accuracy = 0\n",
    "    # else:\n",
    "    #     accuracy = true_positives[c]/ (n_labels[c])\n",
    "    \n",
    "    # print(f\"accuracy for {c}: {accuracy}\")\n",
    "    print(c)\n",
    "    print(f\"precision for {c}: {precision}\")\n",
    "    print(f\"recall for {c}: {recall}\")\n",
    "    print(\"---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf4b60a9-efb9-4011-9ee0-00717cac3cdc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
